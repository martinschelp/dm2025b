{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Tarea para el Hogar 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSICPpyTGQmC"
   },
   "source": [
    "Esta Tarea para el Hogar 02 se entrega el final de la cuarta clase\n",
    "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 05 que será el miercoles 03 de septiembre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  1. Cazatalentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "En la Clase 03 nos hemos enfrentado a  \"La Maldicion del Ganandor\",  elegir el modelo con el mejor puntaje simple no suele ser la mejor estrategia.\n",
    "<br> Lea y ejecute el notebook  **src/CazaTalentos/CazaTalentos.ipynb**\n",
    "<br> en caso de interesarle, participe del Desafío Ordenamiento  que vence el sábado 06 de septiembre a las 19:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9GkTOk5J9t3"
   },
   "source": [
    "## 2. Hiperparámetros del LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmEFy0ukKL5T"
   },
   "source": [
    "Los objetivos de esta tarea son:\n",
    "\n",
    "\n",
    "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
    "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
    "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
    "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
    "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
    "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yvlS6JQLRMd"
   },
   "source": [
    "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
    "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eydI4YNAsFaf"
   },
   "source": [
    "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
    "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzU4S0SeMcpp"
   },
   "source": [
    "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
    "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
    "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNptUgI_NWWG"
   },
   "source": [
    "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
    "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
    "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
    "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
    "\n",
    "\n",
    "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
    "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpUThBojODyK"
   },
   "source": [
    "El desafío de esta tarea es:\n",
    "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
    "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
    "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX0qg_c0yqob"
   },
   "source": [
    "#### 2.1  Seteo del ambiente en Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGY7H9xza7Zr"
   },
   "source": [
    "Esta parte se debe correr con el runtime en Python3\n",
    "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PupIBNba7Zr"
   },
   "source": [
    "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LpZCst5a7Zs"
   },
   "outputs": [],
   "source": [
    "# primero establecer el Runtime de Python 3\n",
    "from google.colab import drive\n",
    "drive.mount('/content/.drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYC_F-wla7Zs"
   },
   "source": [
    "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
    "\n",
    "<br>los siguientes comando estan en shell script de Linux\n",
    "*   Crear las carpetas en el Google Drive\n",
    "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
    "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWLelftXa7Zt"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "mkdir -p \"/content/.drive/My Drive/dm\"\n",
    "mkdir -p \"/content/buckets\"\n",
    "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
    "\n",
    "mkdir -p ~/.kaggle\n",
    "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
    "chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "\n",
    "mkdir -p /content/buckets/b1/exp\n",
    "mkdir -p /content/buckets/b1/datasets\n",
    "mkdir -p /content/datasets\n",
    "\n",
    "\n",
    "\n",
    "archivo_origen=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/dataset_pequeno.csv\"\n",
    "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
    "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
    "\n",
    "if ! test -f $archivo_destino_bucket; then\n",
    "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
    "fi\n",
    "\n",
    "\n",
    "if ! test -f $archivo_destino; then\n",
    "  cp  $archivo_destino_bucket  $archivo_destino\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### 2.2 Optimizacion Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kwPpHAtSmix"
   },
   "source": [
    "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "### 2.2.1 Inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy8YTZfESxeJ"
   },
   "source": [
    "limpio el ambiente de R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gBq__iAdQliq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Mon Sep 08 00:04:36 2025'"
      ],
      "text/latex": [
       "'Mon Sep 08 00:04:36 2025'"
      ],
      "text/markdown": [
       "'Mon Sep 08 00:04:36 2025'"
      ],
      "text/plain": [
       "[1] \"Mon Sep 08 00:04:36 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7rdVrBojS1IV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 658164</td><td>35.2</td><td>1439371</td><td>76.9</td><td>1439371</td><td>76.9</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1227564</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1924961</td><td>14.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  658164 & 35.2 & 1439371 & 76.9 & 1439371 & 76.9\\\\\n",
       "\tVcells & 1227564 &  9.4 & 8388608 & 64.0 & 1924961 & 14.7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  658164 | 35.2 | 1439371 | 76.9 | 1439371 | 76.9 |\n",
       "| Vcells | 1227564 |  9.4 | 8388608 | 64.0 | 1924961 | 14.7 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  658164 35.2 1439371    76.9 1439371  76.9\n",
       "Vcells 1227564  9.4 8388608    64.0 1924961  14.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### 2.2.2 Carga de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lVyxLaJ1j1J_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: primes\n",
      "\n",
      "Loading required package: rlist\n",
      "\n",
      "Loading required package: yaml\n",
      "\n",
      "Loading required package: lightgbm\n",
      "\n",
      "Loading required package: DiceKriging\n",
      "\n",
      "Loading required package: mlrMBO\n",
      "\n",
      "Loading required package: mlr\n",
      "\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "Loading required package: smoof\n",
      "\n",
      "Loading required package: checkmate\n",
      "\n",
      "\n",
      "Attaching package: ‘checkmate’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:DiceKriging’:\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cargo las librerias que necesito\n",
    "require(\"data.table\")\n",
    "require(\"parallel\")\n",
    "\n",
    "if( !require(\"primes\") ) install.packages(\"primes\")\n",
    "require(\"primes\")\n",
    "\n",
    "if( !require(\"utils\") ) install.packages(\"utils\")\n",
    "require(\"utils\")\n",
    "\n",
    "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
    "require(\"rlist\")\n",
    "\n",
    "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
    "require(\"yaml\")\n",
    "\n",
    "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")\n",
    "\n",
    "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz-6Qt6BUaA3"
   },
   "source": [
    "### 2.2.3 Definicion de Parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOdlKd7lUm2I"
   },
   "source": [
    "aqui debe cargar SU semilla primigenia\n",
    "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ASYkebOu2mF6"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- 49408082025\n",
    "PARAM$semilla_primigenia <- 100379\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ezOhQdbA293o"
   },
   "outputs": [],
   "source": [
    "PARAM$kaggle$competencia <- \"data-mining-analista-sr-2025-b\"\n",
    "PARAM$kaggle$cortes <- seq(10000, 12000, by= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jtB0Lub42rHO"
   },
   "outputs": [],
   "source": [
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "# undersampling de 1.0  implica tomar TODOS los datos\n",
    "\n",
    "PARAM$trainingstrategy$undersampling <- 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OFxm-xiNUOJX"
   },
   "outputs": [],
   "source": [
    "# Parametros LightGBM\n",
    "\n",
    "PARAM$hyperparametertuning$xval_folds <- 5\n",
    "\n",
    "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
    "PARAM$lgbm$param_fijos <-  list(\n",
    "  boosting= \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective= \"binary\",\n",
    "  metric= \"auc\",\n",
    "  first_metric_only= FALSE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  force_row_wise= TRUE, # para reducir warnings\n",
    "  verbosity= -100,\n",
    "\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "\n",
    "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
    "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1= 0.03744994, # lambda_l1 >= 0.0\n",
    "  lambda_l2= 2494.496, # lambda_l2 >= 0.0\n",
    "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
    "\n",
    "  bagging_fraction= 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance= FALSE, #\n",
    "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop= 50, # <=0 means no limit\n",
    "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees= FALSE,\n",
    "\n",
    "  num_iterations= 1485,\n",
    "  learning_rate= 0.3908224,\n",
    "  feature_fraction= 0.1525468,\n",
    "  num_leaves= 808,\n",
    "  min_data_in_leaf= 193\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5Yj-JV4yvOt"
   },
   "source": [
    "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
    "<br> si es un numero entero debe ir  makeIntegerParam\n",
    "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
    "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jENpR26ZyuS8"
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
    "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
    "  makeIntegerParam(\"num_iterations\", lower= 8L, upper= 2048L),\n",
    "  makeNumericParam(\"learning_rate\", lower= 0.01, upper= 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower= 0.1, upper= 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower= 8L, upper= 2048L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower= 1L, upper= 8000L),\n",
    "  makeNumericParam(\"lambda_l1\", lower= 0.0, upper= 100.0),\n",
    "  makeNumericParam(\"lambda_l2\", lower= 0.0, upper= 5000.0),\n",
    "  makeNumericParam(\"min_gain_to_split\", lower= 0.0, upper= 10.0),\n",
    "  makeNumericParam(\"bagging_fraction\", lower= 0.0, upper= 1.0),\n",
    "  makeIntegerParam(\"bagging_freq\", lower= 0L, upper= 1000L),\n",
    "  makeNumericParam(\"min_sum_hessian_in_leaf\", lower= 0.0, upper= 100.0)    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_RPFUb3zMoW"
   },
   "source": [
    "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
    "<br> 30 es un valor muy tacaño, pero corre rápido\n",
    "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "q5Rd3pnbzSiG"
   },
   "outputs": [],
   "source": [
    "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RWZXL1VZjMI"
   },
   "source": [
    "### 2.2.4  Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "j3toG9-lZm4K"
   },
   "outputs": [],
   "source": [
    "# carpeta de trabajo\n",
    "\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FM3lxKoLZ643"
   },
   "outputs": [],
   "source": [
    "# lectura del dataset\n",
    "\n",
    "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OsJ-91UeZ-I_"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "vrWE7BE0aB2J"
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "\n",
    "dataset_train[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jP7YlQBnaW6W"
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "# notar que para esto utilizo la SEGUNDA semilla\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train[, azar := runif(nrow(dataset_train))]\n",
    "dataset_train[, training := 0L]\n",
    "\n",
    "dataset_train[\n",
    "  foto_mes %in% c(202107) &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "xElu4s5W4rX7"
   },
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "PppMHcGYaaol"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "83507"
      ],
      "text/latex": [
       "83507"
      ],
      "text/markdown": [
       "83507"
      ],
      "text/plain": [
       "[1] 83507"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "154"
      ],
      "text/latex": [
       "154"
      ],
      "text/markdown": [
       "154"
      ],
      "text/plain": [
       "[1] 154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "nrow(dtrain)\n",
    "ncol(dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta-EkOu3cphF"
   },
   "source": [
    "2.2.5 Configuracion Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "cjgfurjdfiXb"
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la AUC en cross validation del modelo entrenado\n",
    "\n",
    "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  # entreno LightGBM\n",
    "  modelocv <- lgb.cv(\n",
    "    data= dtrain,\n",
    "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
    "    stratified= TRUE,\n",
    "    param= param_completo\n",
    "  )\n",
    "\n",
    "  # obtengo la ganancia\n",
    "  AUC <- modelocv$best_score\n",
    "\n",
    "  # hago espacio en la memoria\n",
    "  rm(modelocv)\n",
    "  gc(full= TRUE, verbose= FALSE)\n",
    "\n",
    "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
    "\n",
    "  return(AUC)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WLi_o1hocvN-"
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "\n",
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "kbayesiana <- \"bayesiana.RDATA\"\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hyperparametertuning$iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uUeVo5pc4zc"
   },
   "source": [
    "2.2.6 Corrida Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "RcABNaKGciaz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing y column(s) for design. Not provided.\n",
      "\n",
      "Mon Sep 08 00:06:30 2025 AUC 0.902302571039574\n",
      "\n",
      "Mon Sep 08 00:06:42 2025 AUC 0.897212092574602\n",
      "\n",
      "Mon Sep 08 00:06:50 2025 AUC 0.90532025017443\n",
      "\n",
      "Mon Sep 08 00:06:55 2025 AUC 0.902051522822469\n",
      "\n",
      "Mon Sep 08 00:07:16 2025 AUC 0.906117770463336\n",
      "\n",
      "Mon Sep 08 00:07:43 2025 AUC 0.907861152086971\n",
      "\n",
      "Mon Sep 08 00:07:53 2025 AUC 0.904054130177561\n",
      "\n",
      "Mon Sep 08 00:08:08 2025 AUC 0.899382270272154\n",
      "\n",
      "Mon Sep 08 00:08:21 2025 AUC 0.908554367441488\n",
      "\n",
      "Mon Sep 08 00:08:39 2025 AUC 0.907089492677052\n",
      "\n",
      "Mon Sep 08 00:08:53 2025 AUC 0.897875562229295\n",
      "\n",
      "Mon Sep 08 00:08:54 2025 AUC 0.875916365928519\n",
      "\n",
      "Mon Sep 08 00:09:01 2025 AUC 0.911513181931453\n",
      "\n",
      "Mon Sep 08 00:09:10 2025 AUC 0.89064194196719\n",
      "\n",
      "Mon Sep 08 00:09:31 2025 AUC 0.908945511870786\n",
      "\n",
      "Mon Sep 08 00:09:44 2025 AUC 0.895489284301203\n",
      "\n",
      "Mon Sep 08 00:10:10 2025 AUC 0.901353257321352\n",
      "\n",
      "Mon Sep 08 00:10:12 2025 AUC 0.906496640108381\n",
      "\n",
      "Mon Sep 08 00:10:19 2025 AUC 0.902099312727028\n",
      "\n",
      "Mon Sep 08 00:10:22 2025 AUC 0.902745062473794\n",
      "\n",
      "Mon Sep 08 00:10:35 2025 AUC 0.90451629290571\n",
      "\n",
      "Mon Sep 08 00:10:52 2025 AUC 0.5\n",
      "\n",
      "Mon Sep 08 00:10:59 2025 AUC 0.891659940561765\n",
      "\n",
      "Mon Sep 08 00:11:18 2025 AUC 0.5\n",
      "\n",
      "Mon Sep 08 00:11:26 2025 AUC 0.900399755253727\n",
      "\n",
      "Mon Sep 08 00:11:36 2025 AUC 0.898170811225485\n",
      "\n",
      "Mon Sep 08 00:11:57 2025 AUC 0.904081831159642\n",
      "\n",
      "Mon Sep 08 00:12:08 2025 AUC 0.912286224155432\n",
      "\n",
      "Mon Sep 08 00:12:15 2025 AUC 0.909918267757359\n",
      "\n",
      "Mon Sep 08 00:12:19 2025 AUC 0.5\n",
      "\n",
      "Mon Sep 08 00:12:22 2025 AUC 0.905978400482188\n",
      "\n",
      "Mon Sep 08 00:12:37 2025 AUC 0.893564307851796\n",
      "\n",
      "Mon Sep 08 00:12:40 2025 AUC 0.904571426614937\n",
      "\n",
      "Mon Sep 08 00:12:55 2025 AUC 0.907155643323976\n",
      "\n",
      "Mon Sep 08 00:13:10 2025 AUC 0.5\n",
      "\n",
      "Mon Sep 08 00:13:12 2025 AUC 0.905586721034302\n",
      "\n",
      "Mon Sep 08 00:13:16 2025 AUC 0.5\n",
      "\n",
      "Mon Sep 08 00:13:22 2025 AUC 0.898337126981745\n",
      "\n",
      "Mon Sep 08 00:13:35 2025 AUC 0.910818400999581\n",
      "\n",
      "Mon Sep 08 00:13:48 2025 AUC 0.913996176423876\n",
      "\n",
      "Mon Sep 08 00:14:04 2025 AUC 0.904753156262475\n",
      "\n",
      "Mon Sep 08 00:14:28 2025 AUC 0.5\n",
      "\n",
      "Mon Sep 08 00:14:33 2025 AUC 0.914361681598602\n",
      "\n",
      "Mon Sep 08 00:14:43 2025 AUC 0.5\n",
      "\n",
      "[mbo] 0: num_iterations=892; learning_rate=0.0909; feature_fraction=0.656; num_leaves=617; min_data_in_leaf=3920; lambda_l1=34.7; lambda_l2=3.14e+03; min_gain_to_split=5.9; bagging_fraction=0.504; bagging_freq=570; min_sum_hessian_in_leaf=58.5 : y = 0.902 : 7.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1938; learning_rate=0.181; feature_fraction=0.942; num_leaves=912; min_data_in_leaf=1873; lambda_l1=74.8; lambda_l2=2.31e+03; min_gain_to_split=4.13; bagging_fraction=0.301; bagging_freq=433; min_sum_hessian_in_leaf=63.5 : y = 0.897 : 11.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1024; learning_rate=0.271; feature_fraction=0.82; num_leaves=1384; min_data_in_leaf=3568; lambda_l1=44.8; lambda_l2=3.01e+03; min_gain_to_split=7.69; bagging_fraction=0.642; bagging_freq=548; min_sum_hessian_in_leaf=39.4 : y = 0.905 : 7.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=600; learning_rate=0.118; feature_fraction=0.581; num_leaves=329; min_data_in_leaf=4087; lambda_l1=14.8; lambda_l2=442; min_gain_to_split=6.69; bagging_fraction=0.294; bagging_freq=489; min_sum_hessian_in_leaf=22.1 : y = 0.902 : 5.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1141; learning_rate=0.11; feature_fraction=0.234; num_leaves=1568; min_data_in_leaf=4842; lambda_l1=67; lambda_l2=1.88e+03; min_gain_to_split=8.66; bagging_fraction=0.771; bagging_freq=420; min_sum_hessian_in_leaf=30.5 : y = 0.906 : 20.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1593; learning_rate=0.149; feature_fraction=0.497; num_leaves=1225; min_data_in_leaf=1708; lambda_l1=48.1; lambda_l2=1.64e+03; min_gain_to_split=2.99; bagging_fraction=0.597; bagging_freq=525; min_sum_hessian_in_leaf=59.1 : y = 0.908 : 27.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1261; learning_rate=0.0328; feature_fraction=0.759; num_leaves=1007; min_data_in_leaf=3397; lambda_l1=10.7; lambda_l2=2.17e+03; min_gain_to_split=4.66; bagging_fraction=0.421; bagging_freq=876; min_sum_hessian_in_leaf=63.8 : y = 0.904 : 9.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1238; learning_rate=0.0863; feature_fraction=0.39; num_leaves=98; min_data_in_leaf=5043; lambda_l1=56.1; lambda_l2=2.66e+03; min_gain_to_split=6.94; bagging_fraction=0.381; bagging_freq=506; min_sum_hessian_in_leaf=85.3 : y = 0.899 : 14.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=625; learning_rate=0.209; feature_fraction=0.537; num_leaves=1296; min_data_in_leaf=2859; lambda_l1=29.8; lambda_l2=2.53e+03; min_gain_to_split=5.59; bagging_fraction=0.843; bagging_freq=157; min_sum_hessian_in_leaf=41.9 : y = 0.909 : 12.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=967; learning_rate=0.264; feature_fraction=0.29; num_leaves=518; min_data_in_leaf=2067; lambda_l1=64.6; lambda_l2=1.48e+03; min_gain_to_split=7.19; bagging_fraction=0.798; bagging_freq=815; min_sum_hessian_in_leaf=54.2 : y = 0.907 : 18.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1110; learning_rate=0.239; feature_fraction=0.316; num_leaves=778; min_data_in_leaf=449; lambda_l1=95.8; lambda_l2=2.92e+03; min_gain_to_split=5.4; bagging_fraction=0.403; bagging_freq=239; min_sum_hessian_in_leaf=44.2 : y = 0.898 : 13.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=45; learning_rate=0.133; feature_fraction=0.418; num_leaves=660; min_data_in_leaf=5986; lambda_l1=28.3; lambda_l2=3.73e+03; min_gain_to_split=3.92; bagging_fraction=0.25; bagging_freq=674; min_sum_hessian_in_leaf=70.2 : y = 0.876 : 1.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=443; learning_rate=0.0294; feature_fraction=0.272; num_leaves=395; min_data_in_leaf=698; lambda_l1=27.2; lambda_l2=205; min_gain_to_split=2.56; bagging_fraction=0.551; bagging_freq=897; min_sum_hessian_in_leaf=11.8 : y = 0.912 : 7.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1379; learning_rate=0.192; feature_fraction=0.627; num_leaves=1637; min_data_in_leaf=2465; lambda_l1=46.5; lambda_l2=2.42e+03; min_gain_to_split=8.46; bagging_fraction=0.243; bagging_freq=385; min_sum_hessian_in_leaf=56.6 : y = 0.891 : 8.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1546; learning_rate=0.0629; feature_fraction=0.202; num_leaves=104; min_data_in_leaf=2947; lambda_l1=1.63; lambda_l2=3.19e+03; min_gain_to_split=1.77; bagging_fraction=0.453; bagging_freq=337; min_sum_hessian_in_leaf=37.1 : y = 0.909 : 20.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1671; learning_rate=0.141; feature_fraction=0.604; num_leaves=1476; min_data_in_leaf=2259; lambda_l1=91.5; lambda_l2=1.81e+03; min_gain_to_split=6.37; bagging_fraction=0.326; bagging_freq=940; min_sum_hessian_in_leaf=13.8 : y = 0.895 : 13.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1487; learning_rate=0.297; feature_fraction=0.336; num_leaves=1804; min_data_in_leaf=6965; lambda_l1=68.5; lambda_l2=4.67e+03; min_gain_to_split=7.48; bagging_fraction=0.711; bagging_freq=464; min_sum_hessian_in_leaf=48.3 : y = 0.901 : 25.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=166; learning_rate=0.2; feature_fraction=0.841; num_leaves=953; min_data_in_leaf=3095; lambda_l1=18.4; lambda_l2=4.46e+03; min_gain_to_split=2.29; bagging_fraction=0.667; bagging_freq=275; min_sum_hessian_in_leaf=90.6 : y = 0.906 : 2.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=842; learning_rate=0.291; feature_fraction=0.637; num_leaves=217; min_data_in_leaf=6221; lambda_l1=23.8; lambda_l2=2.73e+03; min_gain_to_split=9.36; bagging_fraction=0.616; bagging_freq=827; min_sum_hessian_in_leaf=35.6 : y = 0.902 : 7.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=298; learning_rate=0.0598; feature_fraction=0.867; num_leaves=596; min_data_in_leaf=2606; lambda_l1=61.8; lambda_l2=2.09e+03; min_gain_to_split=8.35; bagging_fraction=0.539; bagging_freq=255; min_sum_hessian_in_leaf=46.8 : y = 0.903 : 2.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=705; learning_rate=0.159; feature_fraction=0.153; num_leaves=435; min_data_in_leaf=7767; lambda_l1=78.4; lambda_l2=1.17e+03; min_gain_to_split=9.28; bagging_fraction=0.789; bagging_freq=624; min_sum_hessian_in_leaf=67.8 : y = 0.905 : 12.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1406; learning_rate=0.101; feature_fraction=0.744; num_leaves=733; min_data_in_leaf=7511; lambda_l1=60.8; lambda_l2=1.25e+03; min_gain_to_split=2.76; bagging_fraction=0.195; bagging_freq=651; min_sum_hessian_in_leaf=0.425 : y = 0.5 : 16.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1204; learning_rate=0.252; feature_fraction=0.806; num_leaves=11; min_data_in_leaf=5426; lambda_l1=76.6; lambda_l2=4.05e+03; min_gain_to_split=0.0398; bagging_fraction=0.217; bagging_freq=394; min_sum_hessian_in_leaf=79.2 : y = 0.892 : 7.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1964; learning_rate=0.258; feature_fraction=0.428; num_leaves=1757; min_data_in_leaf=7976; lambda_l1=5.7; lambda_l2=3.31e+03; min_gain_to_split=4.99; bagging_fraction=0.0647; bagging_freq=965; min_sum_hessian_in_leaf=9.83 : y = 0.5 : 19.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=483; learning_rate=0.0157; feature_fraction=0.368; num_leaves=1837; min_data_in_leaf=6805; lambda_l1=41.9; lambda_l2=1.06e+03; min_gain_to_split=8.02; bagging_fraction=0.481; bagging_freq=207; min_sum_hessian_in_leaf=70.6 : y = 0.9 : 7.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1721; learning_rate=0.0554; feature_fraction=0.961; num_leaves=1514; min_data_in_leaf=4494; lambda_l1=99.7; lambda_l2=995; min_gain_to_split=5.11; bagging_fraction=0.347; bagging_freq=703; min_sum_hessian_in_leaf=93 : y = 0.898 : 10.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1311; learning_rate=0.0702; feature_fraction=0.186; num_leaves=1052; min_data_in_leaf=6512; lambda_l1=82.4; lambda_l2=4.86e+03; min_gain_to_split=0.942; bagging_fraction=0.588; bagging_freq=919; min_sum_hessian_in_leaf=88 : y = 0.904 : 21.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1052; learning_rate=0.217; feature_fraction=0.985; num_leaves=1434; min_data_in_leaf=6584; lambda_l1=17.3; lambda_l2=4.31e+03; min_gain_to_split=0.331; bagging_fraction=0.743; bagging_freq=37; min_sum_hessian_in_leaf=3.24 : y = 0.912 : 10.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=751; learning_rate=0.205; feature_fraction=0.705; num_leaves=263; min_data_in_leaf=1227; lambda_l1=94.1; lambda_l2=1.97e+03; min_gain_to_split=0.735; bagging_fraction=0.926; bagging_freq=360; min_sum_hessian_in_leaf=94.8 : y = 0.91 : 6.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=391; learning_rate=0.0824; feature_fraction=0.938; num_leaves=862; min_data_in_leaf=5763; lambda_l1=7.57; lambda_l2=1.49e+03; min_gain_to_split=2.26; bagging_fraction=0.0685; bagging_freq=610; min_sum_hessian_in_leaf=81.5 : y = 0.5 : 3.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=367; learning_rate=0.185; feature_fraction=0.904; num_leaves=1994; min_data_in_leaf=4217; lambda_l1=90.8; lambda_l2=3.45e+03; min_gain_to_split=1.16; bagging_fraction=0.699; bagging_freq=852; min_sum_hessian_in_leaf=25.3 : y = 0.906 : 3.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1790; learning_rate=0.0222; feature_fraction=0.358; num_leaves=1123; min_data_in_leaf=167; lambda_l1=58.4; lambda_l2=631; min_gain_to_split=3.86; bagging_fraction=0.133; bagging_freq=115; min_sum_hessian_in_leaf=32.3 : y = 0.894 : 14.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=112; learning_rate=0.222; feature_fraction=0.129; num_leaves=1724; min_data_in_leaf=1042; lambda_l1=53.6; lambda_l2=4.15e+03; min_gain_to_split=9.87; bagging_fraction=0.945; bagging_freq=77; min_sum_hessian_in_leaf=75.1 : y = 0.905 : 2.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1893; learning_rate=0.108; feature_fraction=0.685; num_leaves=1185; min_data_in_leaf=242; lambda_l1=22.4; lambda_l2=4.66e+03; min_gain_to_split=1.56; bagging_fraction=0.469; bagging_freq=715; min_sum_hessian_in_leaf=4.86 : y = 0.907 : 15.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1833; learning_rate=0.281; feature_fraction=0.719; num_leaves=2005; min_data_in_leaf=6009; lambda_l1=51.8; lambda_l2=761; min_gain_to_split=3.45; bagging_fraction=0.0264; bagging_freq=174; min_sum_hessian_in_leaf=98.3 : y = 0.5 : 14.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=74; learning_rate=0.228; feature_fraction=0.515; num_leaves=1865; min_data_in_leaf=7134; lambda_l1=72.7; lambda_l2=334; min_gain_to_split=4.42; bagging_fraction=0.824; bagging_freq=112; min_sum_hessian_in_leaf=6.85 : y = 0.906 : 2.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=543; learning_rate=0.167; feature_fraction=0.173; num_leaves=1595; min_data_in_leaf=3759; lambda_l1=38.2; lambda_l2=864; min_gain_to_split=7.79; bagging_fraction=0.0221; bagging_freq=766; min_sum_hessian_in_leaf=23.9 : y = 0.5 : 4.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=248; learning_rate=0.0436; feature_fraction=0.461; num_leaves=157; min_data_in_leaf=4687; lambda_l1=79.6; lambda_l2=4.89e+03; min_gain_to_split=6.12; bagging_fraction=0.866; bagging_freq=737; min_sum_hessian_in_leaf=27.4 : y = 0.898 : 6.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=696; learning_rate=0.123; feature_fraction=0.102; num_leaves=816; min_data_in_leaf=5185; lambda_l1=40.8; lambda_l2=3.6e+03; min_gain_to_split=0.665; bagging_fraction=0.16; bagging_freq=0; min_sum_hessian_in_leaf=96.9 : y = 0.911 : 12.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1495; learning_rate=0.247; feature_fraction=0.788; num_leaves=350; min_data_in_leaf=5486; lambda_l1=32.4; lambda_l2=36.3; min_gain_to_split=3.18; bagging_fraction=0.888; bagging_freq=774; min_sum_hessian_in_leaf=74.5 : y = 0.914 : 13.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=1735; learning_rate=0.173; feature_fraction=0.881; num_leaves=1910; min_data_in_leaf=1323; lambda_l1=84.8; lambda_l2=3.94e+03; min_gain_to_split=9; bagging_fraction=0.96; bagging_freq=54; min_sum_hessian_in_leaf=17.8 : y = 0.905 : 15.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=2013; learning_rate=0.144; feature_fraction=0.487; num_leaves=483; min_data_in_leaf=7372; lambda_l1=13.2; lambda_l2=3.8e+03; min_gain_to_split=9.55; bagging_fraction=0.143; bagging_freq=316; min_sum_hessian_in_leaf=20 : y = 0.5 : 24.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=197; learning_rate=0.0373; feature_fraction=0.246; num_leaves=1097; min_data_in_leaf=751; lambda_l1=2.6; lambda_l2=500; min_gain_to_split=1.85; bagging_fraction=0.981; bagging_freq=201; min_sum_hessian_in_leaf=51.4 : y = 0.914 : 5.5 secs : initdesign\n",
      "\n",
      "[mbo] 0: num_iterations=869; learning_rate=0.277; feature_fraction=0.551; num_leaves=1342; min_data_in_leaf=1506; lambda_l1=88; lambda_l2=4.35e+03; min_gain_to_split=6.29; bagging_fraction=0.111; bagging_freq=983; min_sum_hessian_in_leaf=83.7 : y = 0.5 : 10.3 secs : initdesign\n",
      "\n",
      "Mon Sep 08 00:14:50 2025 AUC 0.899050906674421\n",
      "\n",
      "[mbo] 1: num_iterations=458; learning_rate=0.0877; feature_fraction=0.15; num_leaves=772; min_data_in_leaf=1838; lambda_l1=60.2; lambda_l2=3.48e+03; min_gain_to_split=0.299; bagging_fraction=0.249; bagging_freq=35; min_sum_hessian_in_leaf=89.1 : y = 0.899 : 5.4 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:15:00 2025 AUC 0.90611311824741\n",
      "\n",
      "[mbo] 2: num_iterations=721; learning_rate=0.0672; feature_fraction=0.355; num_leaves=1674; min_data_in_leaf=1239; lambda_l1=33.2; lambda_l2=128; min_gain_to_split=8; bagging_fraction=0.326; bagging_freq=382; min_sum_hessian_in_leaf=45.7 : y = 0.906 : 9.1 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:15:04 2025 AUC 0.894219326172692\n",
      "\n",
      "[mbo] 3: num_iterations=506; learning_rate=0.289; feature_fraction=0.7; num_leaves=15; min_data_in_leaf=4773; lambda_l1=42.8; lambda_l2=3.97e+03; min_gain_to_split=2.28; bagging_fraction=0.281; bagging_freq=386; min_sum_hessian_in_leaf=95.8 : y = 0.894 : 3.4 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:15:18 2025 AUC 0.9076494454985\n",
      "\n",
      "[mbo] 4: num_iterations=589; learning_rate=0.163; feature_fraction=0.493; num_leaves=1338; min_data_in_leaf=4723; lambda_l1=51.4; lambda_l2=1.24e+03; min_gain_to_split=6.67; bagging_fraction=0.936; bagging_freq=545; min_sum_hessian_in_leaf=25.6 : y = 0.908 : 13.7 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:15:30 2025 AUC 0.900790372232008\n",
      "\n",
      "[mbo] 5: num_iterations=964; learning_rate=0.0455; feature_fraction=0.108; num_leaves=586; min_data_in_leaf=4258; lambda_l1=51.2; lambda_l2=1.66e+03; min_gain_to_split=0.453; bagging_fraction=0.269; bagging_freq=11; min_sum_hessian_in_leaf=88.2 : y = 0.901 : 11.2 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:15:45 2025 AUC 0.89271925364251\n",
      "\n",
      "[mbo] 6: num_iterations=1367; learning_rate=0.153; feature_fraction=0.403; num_leaves=393; min_data_in_leaf=141; lambda_l1=95.8; lambda_l2=2.71e+03; min_gain_to_split=3.53; bagging_fraction=0.226; bagging_freq=2; min_sum_hessian_in_leaf=74.3 : y = 0.893 : 14.0 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:15:49 2025 AUC 0.897558163038862\n",
      "\n",
      "[mbo] 7: num_iterations=299; learning_rate=0.21; feature_fraction=0.114; num_leaves=421; min_data_in_leaf=5220; lambda_l1=40; lambda_l2=4.65e+03; min_gain_to_split=0.462; bagging_fraction=0.227; bagging_freq=72; min_sum_hessian_in_leaf=80.4 : y = 0.898 : 3.5 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:15:56 2025 AUC 0.910033521873744\n",
      "\n",
      "[mbo] 8: num_iterations=567; learning_rate=0.189; feature_fraction=0.657; num_leaves=691; min_data_in_leaf=6024; lambda_l1=37.7; lambda_l2=1.38e+03; min_gain_to_split=0.417; bagging_fraction=0.721; bagging_freq=485; min_sum_hessian_in_leaf=25.8 : y = 0.91 : 5.8 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:16:17 2025 AUC 0.898777364716321\n",
      "\n",
      "[mbo] 9: num_iterations=1703; learning_rate=0.138; feature_fraction=0.476; num_leaves=1699; min_data_in_leaf=3286; lambda_l1=53.4; lambda_l2=2.94e+03; min_gain_to_split=6.2; bagging_fraction=0.362; bagging_freq=204; min_sum_hessian_in_leaf=54.2 : y = 0.899 : 20.0 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:16:27 2025 AUC 0.902573538261235\n",
      "\n",
      "[mbo] 10: num_iterations=1522; learning_rate=0.0655; feature_fraction=0.716; num_leaves=514; min_data_in_leaf=29; lambda_l1=26.4; lambda_l2=788; min_gain_to_split=5.29; bagging_fraction=0.274; bagging_freq=167; min_sum_hessian_in_leaf=18.9 : y = 0.903 : 9.3 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 11 in the file bayesiana.RDATA.\n",
      "\n",
      "Mon Sep 08 00:16:39 2025 AUC 0.906512966209676\n",
      "\n",
      "[mbo] 11: num_iterations=603; learning_rate=0.0673; feature_fraction=0.362; num_leaves=267; min_data_in_leaf=3322; lambda_l1=24.1; lambda_l2=396; min_gain_to_split=8.27; bagging_fraction=0.44; bagging_freq=296; min_sum_hessian_in_leaf=41.4 : y = 0.907 : 8.3 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:16:49 2025 AUC 0.905207765114171\n",
      "\n",
      "[mbo] 12: num_iterations=535; learning_rate=0.113; feature_fraction=0.279; num_leaves=878; min_data_in_leaf=4970; lambda_l1=44; lambda_l2=4.08e+03; min_gain_to_split=2.38; bagging_fraction=0.606; bagging_freq=271; min_sum_hessian_in_leaf=4.93 : y = 0.905 : 9.2 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:17:00 2025 AUC 0.905775482368892\n",
      "\n",
      "[mbo] 13: num_iterations=1213; learning_rate=0.161; feature_fraction=0.93; num_leaves=929; min_data_in_leaf=6052; lambda_l1=82.9; lambda_l2=3.84e+03; min_gain_to_split=1.68; bagging_fraction=0.812; bagging_freq=621; min_sum_hessian_in_leaf=69.5 : y = 0.906 : 10.3 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:17:18 2025 AUC 0.899584523862311\n",
      "\n",
      "[mbo] 14: num_iterations=1282; learning_rate=0.0267; feature_fraction=0.333; num_leaves=1901; min_data_in_leaf=77; lambda_l1=21.1; lambda_l2=3.79e+03; min_gain_to_split=1.17; bagging_fraction=0.219; bagging_freq=6; min_sum_hessian_in_leaf=69.7 : y = 0.9 : 16.5 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:17:30 2025 AUC 0.901777323945748\n",
      "\n",
      "[mbo] 15: num_iterations=1089; learning_rate=0.169; feature_fraction=0.431; num_leaves=1235; min_data_in_leaf=467; lambda_l1=5.25; lambda_l2=629; min_gain_to_split=8.64; bagging_fraction=0.264; bagging_freq=44; min_sum_hessian_in_leaf=89.6 : y = 0.902 : 11.3 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:17:47 2025 AUC 0.905061109059413\n",
      "\n",
      "[mbo] 16: num_iterations=1194; learning_rate=0.162; feature_fraction=0.195; num_leaves=1185; min_data_in_leaf=2578; lambda_l1=89.7; lambda_l2=1.36e+03; min_gain_to_split=2.08; bagging_fraction=0.468; bagging_freq=787; min_sum_hessian_in_leaf=20.8 : y = 0.905 : 16.3 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:18:07 2025 AUC 0.902731327602577\n",
      "\n",
      "[mbo] 17: num_iterations=1802; learning_rate=0.03; feature_fraction=0.173; num_leaves=1495; min_data_in_leaf=110; lambda_l1=57.7; lambda_l2=678; min_gain_to_split=3.05; bagging_fraction=0.27; bagging_freq=19; min_sum_hessian_in_leaf=61.2 : y = 0.903 : 19.2 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:18:20 2025 AUC 0.899347909322762\n",
      "\n",
      "[mbo] 18: num_iterations=750; learning_rate=0.118; feature_fraction=0.235; num_leaves=1556; min_data_in_leaf=5086; lambda_l1=88.7; lambda_l2=3.46e+03; min_gain_to_split=1.02; bagging_fraction=0.273; bagging_freq=2; min_sum_hessian_in_leaf=99.2 : y = 0.899 : 11.6 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:18:24 2025 AUC 0.906139191132792\n",
      "\n",
      "[mbo] 19: num_iterations=305; learning_rate=0.0739; feature_fraction=0.233; num_leaves=89; min_data_in_leaf=601; lambda_l1=14.1; lambda_l2=769; min_gain_to_split=5.76; bagging_fraction=0.329; bagging_freq=718; min_sum_hessian_in_leaf=48 : y = 0.906 : 3.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:18:54 2025 AUC 0.909940909530253\n",
      "\n",
      "[mbo] 20: num_iterations=1324; learning_rate=0.0577; feature_fraction=0.31; num_leaves=706; min_data_in_leaf=1408; lambda_l1=57.3; lambda_l2=343; min_gain_to_split=6.11; bagging_fraction=0.908; bagging_freq=262; min_sum_hessian_in_leaf=68.7 : y = 0.91 : 28.4 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:18:57 2025 AUC 0.895522745361432\n",
      "\n",
      "[mbo] 21: num_iterations=200; learning_rate=0.07; feature_fraction=0.274; num_leaves=1066; min_data_in_leaf=3964; lambda_l1=14.8; lambda_l2=3.4e+03; min_gain_to_split=2.8; bagging_fraction=0.343; bagging_freq=605; min_sum_hessian_in_leaf=45.1 : y = 0.896 : 2.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:19:00 2025 AUC 0.902666104896914\n",
      "\n",
      "[mbo] 22: num_iterations=199; learning_rate=0.137; feature_fraction=0.725; num_leaves=1606; min_data_in_leaf=6499; lambda_l1=72.8; lambda_l2=2.19e+03; min_gain_to_split=5.86; bagging_fraction=0.644; bagging_freq=328; min_sum_hessian_in_leaf=85.8 : y = 0.903 : 2.2 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:19:29 2025 AUC 0.912060580762499\n",
      "\n",
      "[mbo] 23: num_iterations=1199; learning_rate=0.157; feature_fraction=0.444; num_leaves=646; min_data_in_leaf=4616; lambda_l1=12.7; lambda_l2=3.55e+03; min_gain_to_split=2.12; bagging_fraction=0.955; bagging_freq=134; min_sum_hessian_in_leaf=58.7 : y = 0.912 : 27.7 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:19:53 2025 AUC 0.908254516850381\n",
      "\n",
      "[mbo] 24: num_iterations=1238; learning_rate=0.0756; feature_fraction=0.329; num_leaves=405; min_data_in_leaf=2754; lambda_l1=22.1; lambda_l2=3.97e+03; min_gain_to_split=2.9; bagging_fraction=0.677; bagging_freq=806; min_sum_hessian_in_leaf=13.4 : y = 0.908 : 22.5 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:20:10 2025 AUC 0.909926161492172\n",
      "\n",
      "[mbo] 25: num_iterations=741; learning_rate=0.142; feature_fraction=0.338; num_leaves=768; min_data_in_leaf=1449; lambda_l1=42.4; lambda_l2=3.05e+03; min_gain_to_split=3.49; bagging_fraction=0.952; bagging_freq=486; min_sum_hessian_in_leaf=24.4 : y = 0.91 : 16.8 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:20:15 2025 AUC 0.911271512473749\n",
      "\n",
      "[mbo] 26: num_iterations=134; learning_rate=0.103; feature_fraction=0.438; num_leaves=579; min_data_in_leaf=3896; lambda_l1=30.3; lambda_l2=973; min_gain_to_split=2.14; bagging_fraction=0.892; bagging_freq=653; min_sum_hessian_in_leaf=83.9 : y = 0.911 : 3.8 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:21:58 2025 AUC 0.909724069645965\n",
      "\n",
      "[mbo] 37: num_iterations=1168; learning_rate=0.0857; feature_fraction=0.756; num_leaves=1623; min_data_in_leaf=6755; lambda_l1=7.55; lambda_l2=4.2e+03; min_gain_to_split=0.954; bagging_fraction=0.664; bagging_freq=722; min_sum_hessian_in_leaf=47.1 : y = 0.91 : 11.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:22:08 2025 AUC 0.909257018574504\n",
      "\n",
      "[mbo] 38: num_iterations=597; learning_rate=0.156; feature_fraction=0.42; num_leaves=1910; min_data_in_leaf=2203; lambda_l1=1.13; lambda_l2=1.7e+03; min_gain_to_split=3.82; bagging_fraction=0.544; bagging_freq=281; min_sum_hessian_in_leaf=14.4 : y = 0.909 : 9.7 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:22:20 2025 AUC 0.908738569222232\n",
      "\n",
      "[mbo] 39: num_iterations=895; learning_rate=0.177; feature_fraction=0.206; num_leaves=347; min_data_in_leaf=2971; lambda_l1=12.4; lambda_l2=119; min_gain_to_split=3.66; bagging_fraction=0.367; bagging_freq=596; min_sum_hessian_in_leaf=21.3 : y = 0.909 : 10.3 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:22:33 2025 AUC 0.908284610278967\n",
      "\n",
      "[mbo] 40: num_iterations=897; learning_rate=0.111; feature_fraction=0.407; num_leaves=657; min_data_in_leaf=1025; lambda_l1=15.8; lambda_l2=1.26e+03; min_gain_to_split=3.25; bagging_fraction=0.456; bagging_freq=511; min_sum_hessian_in_leaf=46.7 : y = 0.908 : 12.5 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:22:40 2025 AUC 0.911657337997892\n",
      "\n",
      "[mbo] 41: num_iterations=469; learning_rate=0.114; feature_fraction=0.865; num_leaves=1450; min_data_in_leaf=636; lambda_l1=3.2; lambda_l2=2.2e+03; min_gain_to_split=5.69; bagging_fraction=0.934; bagging_freq=186; min_sum_hessian_in_leaf=78.2 : y = 0.912 : 5.2 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:23:05 2025 AUC 0.906930892979903\n",
      "\n",
      "[mbo] 42: num_iterations=1468; learning_rate=0.0618; feature_fraction=0.477; num_leaves=345; min_data_in_leaf=211; lambda_l1=74.4; lambda_l2=2.91e+03; min_gain_to_split=0.986; bagging_fraction=0.543; bagging_freq=322; min_sum_hessian_in_leaf=3.16 : y = 0.907 : 23.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:23:19 2025 AUC 0.908141254087131\n",
      "\n",
      "[mbo] 43: num_iterations=1486; learning_rate=0.209; feature_fraction=0.809; num_leaves=1513; min_data_in_leaf=6751; lambda_l1=7.3; lambda_l2=1.05e+03; min_gain_to_split=6.64; bagging_fraction=0.801; bagging_freq=303; min_sum_hessian_in_leaf=62 : y = 0.908 : 12.7 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:23:43 2025 AUC 0.904208966336326\n",
      "\n",
      "[mbo] 44: num_iterations=1695; learning_rate=0.021; feature_fraction=0.389; num_leaves=223; min_data_in_leaf=103; lambda_l1=51.1; lambda_l2=1.19e+03; min_gain_to_split=7.04; bagging_fraction=0.419; bagging_freq=719; min_sum_hessian_in_leaf=21.2 : y = 0.904 : 22.7 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:23:52 2025 AUC 0.909745927645776\n",
      "\n",
      "[mbo] 45: num_iterations=896; learning_rate=0.0963; feature_fraction=0.902; num_leaves=626; min_data_in_leaf=3139; lambda_l1=62.2; lambda_l2=181; min_gain_to_split=3.09; bagging_fraction=0.814; bagging_freq=441; min_sum_hessian_in_leaf=25.4 : y = 0.91 : 8.4 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:24:04 2025 AUC 0.904145101569613\n",
      "\n",
      "[mbo] 46: num_iterations=1393; learning_rate=0.147; feature_fraction=0.848; num_leaves=293; min_data_in_leaf=4991; lambda_l1=87.9; lambda_l2=4.27e+03; min_gain_to_split=2.07; bagging_fraction=0.685; bagging_freq=119; min_sum_hessian_in_leaf=53 : y = 0.904 : 10.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:24:13 2025 AUC 0.910182990306416\n",
      "\n",
      "[mbo] 47: num_iterations=439; learning_rate=0.0528; feature_fraction=0.368; num_leaves=202; min_data_in_leaf=2347; lambda_l1=2.02; lambda_l2=856; min_gain_to_split=6.7; bagging_fraction=0.648; bagging_freq=186; min_sum_hessian_in_leaf=25.9 : y = 0.91 : 8.3 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:24:40 2025 AUC 0.922565507489858\n",
      "\n",
      "[mbo] 48: num_iterations=1118; learning_rate=0.257; feature_fraction=0.438; num_leaves=1257; min_data_in_leaf=704; lambda_l1=5.61; lambda_l2=254; min_gain_to_split=1.11; bagging_fraction=0.934; bagging_freq=423; min_sum_hessian_in_leaf=64.4 : y = 0.923 : 25.6 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:24:55 2025 AUC 0.909493247845403\n",
      "\n",
      "[mbo] 49: num_iterations=595; learning_rate=0.245; feature_fraction=0.348; num_leaves=1696; min_data_in_leaf=1088; lambda_l1=76.8; lambda_l2=807; min_gain_to_split=3.19; bagging_fraction=0.965; bagging_freq=74; min_sum_hessian_in_leaf=76 : y = 0.909 : 14.1 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:25:10 2025 AUC 0.902769449491885\n",
      "\n",
      "[mbo] 50: num_iterations=1226; learning_rate=0.0752; feature_fraction=0.124; num_leaves=1598; min_data_in_leaf=1647; lambda_l1=13.4; lambda_l2=2.35e+03; min_gain_to_split=4.72; bagging_fraction=0.309; bagging_freq=38; min_sum_hessian_in_leaf=64.8 : y = 0.903 : 13.4 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:25:21 2025 AUC 0.909027106133931\n",
      "\n",
      "[mbo] 51: num_iterations=957; learning_rate=0.0546; feature_fraction=0.733; num_leaves=1800; min_data_in_leaf=1055; lambda_l1=45.2; lambda_l2=4.59e+03; min_gain_to_split=1.6; bagging_fraction=0.731; bagging_freq=194; min_sum_hessian_in_leaf=59.1 : y = 0.909 : 10.4 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:25:43 2025 AUC 0.906326961587214\n",
      "\n",
      "[mbo] 52: num_iterations=1376; learning_rate=0.109; feature_fraction=0.319; num_leaves=129; min_data_in_leaf=5753; lambda_l1=22; lambda_l2=522; min_gain_to_split=4.18; bagging_fraction=0.545; bagging_freq=269; min_sum_hessian_in_leaf=7.28 : y = 0.906 : 20.3 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:25:54 2025 AUC 0.90064728034141\n",
      "\n",
      "[mbo] 53: num_iterations=1642; learning_rate=0.152; feature_fraction=0.971; num_leaves=1928; min_data_in_leaf=1281; lambda_l1=97.5; lambda_l2=1.64e+03; min_gain_to_split=7.34; bagging_fraction=0.437; bagging_freq=604; min_sum_hessian_in_leaf=57.3 : y = 0.901 : 10.5 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:26:08 2025 AUC 0.915603206791948\n",
      "\n",
      "[mbo] 54: num_iterations=1370; learning_rate=0.196; feature_fraction=0.818; num_leaves=2016; min_data_in_leaf=2946; lambda_l1=21.9; lambda_l2=204; min_gain_to_split=1.45; bagging_fraction=0.7; bagging_freq=67; min_sum_hessian_in_leaf=11.1 : y = 0.916 : 12.3 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:26:24 2025 AUC 0.912401418415642\n",
      "\n",
      "[mbo] 55: num_iterations=1646; learning_rate=0.288; feature_fraction=0.704; num_leaves=1735; min_data_in_leaf=1924; lambda_l1=30.9; lambda_l2=4.89e+03; min_gain_to_split=0.819; bagging_fraction=0.902; bagging_freq=566; min_sum_hessian_in_leaf=58.4 : y = 0.912 : 14.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:26:32 2025 AUC 0.911026820750534\n",
      "\n",
      "[mbo] 56: num_iterations=746; learning_rate=0.146; feature_fraction=0.957; num_leaves=977; min_data_in_leaf=1454; lambda_l1=58.7; lambda_l2=1.23e+03; min_gain_to_split=2.2; bagging_fraction=0.973; bagging_freq=810; min_sum_hessian_in_leaf=60.8 : y = 0.911 : 7.1 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 57 in the file bayesiana.RDATA.\n",
      "\n",
      "Mon Sep 08 00:26:51 2025 AUC 0.909544608311909\n",
      "\n",
      "[mbo] 57: num_iterations=1023; learning_rate=0.0148; feature_fraction=0.955; num_leaves=1354; min_data_in_leaf=2499; lambda_l1=11.2; lambda_l2=1.53e+03; min_gain_to_split=0.443; bagging_fraction=0.612; bagging_freq=242; min_sum_hessian_in_leaf=12.7 : y = 0.91 : 11.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:27:07 2025 AUC 0.921490793746932\n",
      "\n",
      "[mbo] 58: num_iterations=1318; learning_rate=0.219; feature_fraction=0.722; num_leaves=1877; min_data_in_leaf=2453; lambda_l1=16.8; lambda_l2=1.77e+03; min_gain_to_split=0.0619; bagging_fraction=0.795; bagging_freq=514; min_sum_hessian_in_leaf=7.77 : y = 0.921 : 14.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:27:23 2025 AUC 0.915486684119411\n",
      "\n",
      "[mbo] 59: num_iterations=1522; learning_rate=0.156; feature_fraction=0.667; num_leaves=1947; min_data_in_leaf=291; lambda_l1=37.5; lambda_l2=559; min_gain_to_split=0.698; bagging_fraction=0.865; bagging_freq=906; min_sum_hessian_in_leaf=43.7 : y = 0.915 : 14.1 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:29:07 2025 AUC 0.908838472937552\n",
      "\n",
      "[mbo] 66: num_iterations=1326; learning_rate=0.258; feature_fraction=0.734; num_leaves=1808; min_data_in_leaf=2919; lambda_l1=87; lambda_l2=878; min_gain_to_split=1.16; bagging_fraction=0.878; bagging_freq=627; min_sum_hessian_in_leaf=23.8 : y = 0.909 : 11.3 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:29:28 2025 AUC 0.913487972810668\n",
      "\n",
      "[mbo] 67: num_iterations=1380; learning_rate=0.209; feature_fraction=0.597; num_leaves=1746; min_data_in_leaf=4787; lambda_l1=16.7; lambda_l2=3.43e+03; min_gain_to_split=0.372; bagging_fraction=0.733; bagging_freq=293; min_sum_hessian_in_leaf=58.3 : y = 0.913 : 19.6 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:29:42 2025 AUC 0.915873843574498\n",
      "\n",
      "[mbo] 68: num_iterations=1522; learning_rate=0.119; feature_fraction=0.844; num_leaves=1427; min_data_in_leaf=2065; lambda_l1=13.7; lambda_l2=449; min_gain_to_split=2.32; bagging_fraction=0.746; bagging_freq=830; min_sum_hessian_in_leaf=43.1 : y = 0.916 : 13.2 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:29:53 2025 AUC 0.924792538087469\n",
      "\n",
      "[mbo] 69: num_iterations=778; learning_rate=0.196; feature_fraction=0.907; num_leaves=1338; min_data_in_leaf=1906; lambda_l1=0.481; lambda_l2=21.1; min_gain_to_split=0.418; bagging_fraction=0.866; bagging_freq=207; min_sum_hessian_in_leaf=62.4 : y = 0.925 : 9.4 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:30:06 2025 AUC 0.902729319519236\n",
      "\n",
      "[mbo] 70: num_iterations=1741; learning_rate=0.275; feature_fraction=0.838; num_leaves=54; min_data_in_leaf=3410; lambda_l1=93.4; lambda_l2=3.64e+03; min_gain_to_split=0.0373; bagging_fraction=0.42; bagging_freq=604; min_sum_hessian_in_leaf=78.4 : y = 0.903 : 12.0 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:30:25 2025 AUC 0.918846453076834\n",
      "\n",
      "[mbo] 71: num_iterations=1161; learning_rate=0.0753; feature_fraction=0.687; num_leaves=1905; min_data_in_leaf=6064; lambda_l1=10.3; lambda_l2=2.32e+03; min_gain_to_split=0.0638; bagging_fraction=0.875; bagging_freq=442; min_sum_hessian_in_leaf=8.47 : y = 0.919 : 17.7 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:30:43 2025 AUC 0.909728625273091\n",
      "\n",
      "[mbo] 72: num_iterations=860; learning_rate=0.208; feature_fraction=0.173; num_leaves=1542; min_data_in_leaf=7049; lambda_l1=16.9; lambda_l2=2.29e+03; min_gain_to_split=2.5; bagging_fraction=0.869; bagging_freq=846; min_sum_hessian_in_leaf=56.4 : y = 0.91 : 16.8 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:30:58 2025 AUC 0.924486912193249\n",
      "\n",
      "[mbo] 73: num_iterations=1010; learning_rate=0.189; feature_fraction=0.756; num_leaves=107; min_data_in_leaf=922; lambda_l1=3.24; lambda_l2=838; min_gain_to_split=0.234; bagging_fraction=0.876; bagging_freq=702; min_sum_hessian_in_leaf=24 : y = 0.924 : 13.2 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:31:12 2025 AUC 0.918944629128492\n",
      "\n",
      "[mbo] 74: num_iterations=1356; learning_rate=0.188; feature_fraction=0.711; num_leaves=867; min_data_in_leaf=1632; lambda_l1=5.11; lambda_l2=1.36e+03; min_gain_to_split=0.911; bagging_fraction=0.881; bagging_freq=500; min_sum_hessian_in_leaf=53.2 : y = 0.919 : 13.0 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:31:19 2025 AUC 0.915534321784215\n",
      "\n",
      "[mbo] 75: num_iterations=377; learning_rate=0.0177; feature_fraction=0.88; num_leaves=1927; min_data_in_leaf=4010; lambda_l1=9.57; lambda_l2=146; min_gain_to_split=0.524; bagging_fraction=0.786; bagging_freq=136; min_sum_hessian_in_leaf=19.1 : y = 0.916 : 6.0 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:31:30 2025 AUC 0.900291072726927\n",
      "\n",
      "[mbo] 76: num_iterations=721; learning_rate=0.114; feature_fraction=0.119; num_leaves=1436; min_data_in_leaf=3744; lambda_l1=12.2; lambda_l2=3.01e+03; min_gain_to_split=0.678; bagging_fraction=0.217; bagging_freq=4; min_sum_hessian_in_leaf=95.2 : y = 0.9 : 9.0 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:31:38 2025 AUC 0.919069280874373\n",
      "\n",
      "[mbo] 77: num_iterations=644; learning_rate=0.16; feature_fraction=0.875; num_leaves=1525; min_data_in_leaf=2975; lambda_l1=2.39; lambda_l2=607; min_gain_to_split=1.52; bagging_fraction=0.841; bagging_freq=759; min_sum_hessian_in_leaf=5.75 : y = 0.919 : 6.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:31:46 2025 AUC 0.908765214344876\n",
      "\n",
      "[mbo] 78: num_iterations=512; learning_rate=0.16; feature_fraction=0.913; num_leaves=2014; min_data_in_leaf=6045; lambda_l1=44.6; lambda_l2=4.54e+03; min_gain_to_split=1.54; bagging_fraction=0.907; bagging_freq=35; min_sum_hessian_in_leaf=53.2 : y = 0.909 : 5.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:31:55 2025 AUC 0.919037288288601\n",
      "\n",
      "[mbo] 79: num_iterations=369; learning_rate=0.132; feature_fraction=0.133; num_leaves=151; min_data_in_leaf=480; lambda_l1=24.1; lambda_l2=208; min_gain_to_split=0.148; bagging_fraction=0.815; bagging_freq=809; min_sum_hessian_in_leaf=39.5 : y = 0.919 : 7.7 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:32:08 2025 AUC 0.922622753637308\n",
      "\n",
      "[mbo] 80: num_iterations=555; learning_rate=0.157; feature_fraction=0.574; num_leaves=162; min_data_in_leaf=1939; lambda_l1=9.25; lambda_l2=4.56; min_gain_to_split=1.36; bagging_fraction=0.917; bagging_freq=235; min_sum_hessian_in_leaf=3.01 : y = 0.923 : 11.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:32:21 2025 AUC 0.897239916837746\n",
      "\n",
      "[mbo] 81: num_iterations=1132; learning_rate=0.0856; feature_fraction=0.18; num_leaves=567; min_data_in_leaf=4523; lambda_l1=56.3; lambda_l2=3.93e+03; min_gain_to_split=0.0259; bagging_fraction=0.192; bagging_freq=10; min_sum_hessian_in_leaf=99.8 : y = 0.897 : 12.3 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:32:49 2025 AUC 0.927116109565286\n",
      "\n",
      "[mbo] 82: num_iterations=1135; learning_rate=0.131; feature_fraction=0.523; num_leaves=1457; min_data_in_leaf=489; lambda_l1=4.35; lambda_l2=53.8; min_gain_to_split=0.356; bagging_fraction=0.818; bagging_freq=56; min_sum_hessian_in_leaf=16.1 : y = 0.927 : 26.4 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:33:06 2025 AUC 0.914001947523379\n",
      "\n",
      "[mbo] 83: num_iterations=1419; learning_rate=0.225; feature_fraction=0.965; num_leaves=1632; min_data_in_leaf=2321; lambda_l1=39.7; lambda_l2=4.47e+03; min_gain_to_split=0.00786; bagging_fraction=0.565; bagging_freq=183; min_sum_hessian_in_leaf=16.4 : y = 0.914 : 15.0 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:33:33 2025 AUC 0.927394211784483\n",
      "\n",
      "[mbo] 84: num_iterations=902; learning_rate=0.0929; feature_fraction=0.265; num_leaves=1886; min_data_in_leaf=598; lambda_l1=0.348; lambda_l2=183; min_gain_to_split=0.245; bagging_fraction=0.779; bagging_freq=740; min_sum_hessian_in_leaf=9.1 : y = 0.927 : 25.7 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:33:54 2025 AUC 0.917992561821699\n",
      "\n",
      "[mbo] 85: num_iterations=761; learning_rate=0.137; feature_fraction=0.309; num_leaves=1926; min_data_in_leaf=3053; lambda_l1=6.98; lambda_l2=4.52e+03; min_gain_to_split=0.159; bagging_fraction=0.819; bagging_freq=588; min_sum_hessian_in_leaf=3.64 : y = 0.918 : 18.8 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:35:39 2025 AUC 0.925608478725008\n",
      "\n",
      "[mbo] 90: num_iterations=949; learning_rate=0.0328; feature_fraction=0.881; num_leaves=36; min_data_in_leaf=14; lambda_l1=15.8; lambda_l2=17.3; min_gain_to_split=0.00631; bagging_fraction=0.941; bagging_freq=306; min_sum_hessian_in_leaf=55.3 : y = 0.926 : 18.8 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:35:52 2025 AUC 0.924493450539891\n",
      "\n",
      "[mbo] 91: num_iterations=690; learning_rate=0.105; feature_fraction=0.72; num_leaves=183; min_data_in_leaf=622; lambda_l1=12.4; lambda_l2=174; min_gain_to_split=0.0121; bagging_fraction=0.793; bagging_freq=232; min_sum_hessian_in_leaf=66.3 : y = 0.924 : 11.8 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:36:25 2025 AUC 0.91808698754547\n",
      "\n",
      "[mbo] 92: num_iterations=1555; learning_rate=0.0555; feature_fraction=0.355; num_leaves=29; min_data_in_leaf=4922; lambda_l1=0.695; lambda_l2=298; min_gain_to_split=1.91; bagging_fraction=0.793; bagging_freq=697; min_sum_hessian_in_leaf=47.3 : y = 0.918 : 31.4 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:36:54 2025 AUC 0.921649658218948\n",
      "\n",
      "[mbo] 93: num_iterations=1105; learning_rate=0.1; feature_fraction=0.321; num_leaves=157; min_data_in_leaf=328; lambda_l1=1.4; lambda_l2=4.57; min_gain_to_split=0.0967; bagging_fraction=0.71; bagging_freq=774; min_sum_hessian_in_leaf=98 : y = 0.922 : 27.1 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 94 in the file bayesiana.RDATA.\n",
      "\n",
      "Mon Sep 08 00:37:17 2025 AUC 0.922235998186377\n",
      "\n",
      "[mbo] 94: num_iterations=658; learning_rate=0.233; feature_fraction=0.315; num_leaves=1789; min_data_in_leaf=712; lambda_l1=1.17; lambda_l2=163; min_gain_to_split=0.0704; bagging_fraction=0.787; bagging_freq=812; min_sum_hessian_in_leaf=98.8 : y = 0.922 : 17.4 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:37:30 2025 AUC 0.923399863065162\n",
      "\n",
      "[mbo] 95: num_iterations=1155; learning_rate=0.234; feature_fraction=0.901; num_leaves=50; min_data_in_leaf=39; lambda_l1=4.87; lambda_l2=723; min_gain_to_split=0.34; bagging_fraction=0.657; bagging_freq=183; min_sum_hessian_in_leaf=35.3 : y = 0.923 : 10.9 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:37:36 2025 AUC 0.904682600157652\n",
      "\n",
      "[mbo] 96: num_iterations=190; learning_rate=0.0789; feature_fraction=0.286; num_leaves=1945; min_data_in_leaf=898; lambda_l1=49.2; lambda_l2=3.67e+03; min_gain_to_split=0.394; bagging_fraction=0.813; bagging_freq=779; min_sum_hessian_in_leaf=67.9 : y = 0.905 : 4.7 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:37:59 2025 AUC 0.909345519949776\n",
      "\n",
      "[mbo] 97: num_iterations=1142; learning_rate=0.265; feature_fraction=0.375; num_leaves=1028; min_data_in_leaf=89; lambda_l1=0.597; lambda_l2=1.42e+03; min_gain_to_split=6.84; bagging_fraction=0.701; bagging_freq=626; min_sum_hessian_in_leaf=20.8 : y = 0.909 : 21.1 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:38:10 2025 AUC 0.924233584606694\n",
      "\n",
      "[mbo] 98: num_iterations=643; learning_rate=0.26; feature_fraction=0.82; num_leaves=66; min_data_in_leaf=557; lambda_l1=0.747; lambda_l2=83.6; min_gain_to_split=0.188; bagging_fraction=0.773; bagging_freq=779; min_sum_hessian_in_leaf=74.2 : y = 0.924 : 9.2 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:38:41 2025 AUC 0.90909294640833\n",
      "\n",
      "[mbo] 99: num_iterations=1531; learning_rate=0.147; feature_fraction=0.148; num_leaves=1847; min_data_in_leaf=3146; lambda_l1=71.7; lambda_l2=4.31e+03; min_gain_to_split=1.59; bagging_fraction=0.893; bagging_freq=208; min_sum_hessian_in_leaf=18 : y = 0.909 : 29.5 secs : infill_ei\n",
      "\n",
      "Mon Sep 08 00:38:58 2025 AUC 0.921035392539449\n",
      "\n",
      "[mbo] 100: num_iterations=693; learning_rate=0.0919; feature_fraction=0.247; num_leaves=1945; min_data_in_leaf=6052; lambda_l1=4.01; lambda_l2=16.4; min_gain_to_split=0.96; bagging_fraction=0.806; bagging_freq=352; min_sum_hessian_in_leaf=63.3 : y = 0.921 : 14.9 secs : infill_ei\n",
      "\n",
      "Saved the final state in the file bayesiana.RDATA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "# es la celda mas lenta de todo el notebook\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ssk5nnMk6INK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'num_iterations'</li><li>'learning_rate'</li><li>'feature_fraction'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'lambda_l1'</li><li>'lambda_l2'</li><li>'min_gain_to_split'</li><li>'bagging_fraction'</li><li>'bagging_freq'</li><li>'min_sum_hessian_in_leaf'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_iterations'\n",
       "\\item 'learning\\_rate'\n",
       "\\item 'feature\\_fraction'\n",
       "\\item 'num\\_leaves'\n",
       "\\item 'min\\_data\\_in\\_leaf'\n",
       "\\item 'lambda\\_l1'\n",
       "\\item 'lambda\\_l2'\n",
       "\\item 'min\\_gain\\_to\\_split'\n",
       "\\item 'bagging\\_fraction'\n",
       "\\item 'bagging\\_freq'\n",
       "\\item 'min\\_sum\\_hessian\\_in\\_leaf'\n",
       "\\item 'y'\n",
       "\\item 'dob'\n",
       "\\item 'eol'\n",
       "\\item 'error.message'\n",
       "\\item 'exec.time'\n",
       "\\item 'ei'\n",
       "\\item 'error.model'\n",
       "\\item 'train.time'\n",
       "\\item 'prop.type'\n",
       "\\item 'propose.time'\n",
       "\\item 'se'\n",
       "\\item 'mean'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_iterations'\n",
       "2. 'learning_rate'\n",
       "3. 'feature_fraction'\n",
       "4. 'num_leaves'\n",
       "5. 'min_data_in_leaf'\n",
       "6. 'lambda_l1'\n",
       "7. 'lambda_l2'\n",
       "8. 'min_gain_to_split'\n",
       "9. 'bagging_fraction'\n",
       "10. 'bagging_freq'\n",
       "11. 'min_sum_hessian_in_leaf'\n",
       "12. 'y'\n",
       "13. 'dob'\n",
       "14. 'eol'\n",
       "15. 'error.message'\n",
       "16. 'exec.time'\n",
       "17. 'ei'\n",
       "18. 'error.model'\n",
       "19. 'train.time'\n",
       "20. 'prop.type'\n",
       "21. 'propose.time'\n",
       "22. 'se'\n",
       "23. 'mean'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_iterations\"          \"learning_rate\"          \n",
       " [3] \"feature_fraction\"        \"num_leaves\"             \n",
       " [5] \"min_data_in_leaf\"        \"lambda_l1\"              \n",
       " [7] \"lambda_l2\"               \"min_gain_to_split\"      \n",
       " [9] \"bagging_fraction\"        \"bagging_freq\"           \n",
       "[11] \"min_sum_hessian_in_leaf\" \"y\"                      \n",
       "[13] \"dob\"                     \"eol\"                    \n",
       "[15] \"error.message\"           \"exec.time\"              \n",
       "[17] \"ei\"                      \"error.model\"            \n",
       "[19] \"train.time\"              \"prop.type\"              \n",
       "[21] \"propose.time\"            \"se\"                     \n",
       "[23] \"mean\"                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "colnames( tb_bayesiana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "u4zq-vknhjGc"
   },
   "outputs": [],
   "source": [
    "# almaceno los resultados de la Bayesian Optimization\n",
    "# y capturo los mejores hiperparametros encontrados\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "\n",
    "tb_bayesiana[, iter := .I]\n",
    "\n",
    "# ordeno en forma descendente por AUC = y\n",
    "setorder(tb_bayesiana, -y)\n",
    "\n",
    "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
    "fwrite( tb_bayesiana,\n",
    "  file= \"BO_log.txt\",\n",
    "  sep= \"\\t\"\n",
    ")\n",
    "\n",
    "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
    "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
    "  1, # el primero es el de mejor AUC\n",
    "  setdiff(colnames(tb_bayesiana),\n",
    "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
    "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
    "  with= FALSE\n",
    "]\n",
    "\n",
    "\n",
    "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "E8v2eA427N8e"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "iBTWexVU7PGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_iterations learning_rate feature_fraction num_leaves min_data_in_leaf\n",
      "            <int>         <num>            <num>      <int>            <int>\n",
      "1:            902    0.09287609        0.2646313       1886              598\n",
      "   lambda_l1 lambda_l2 min_gain_to_split bagging_fraction bagging_freq\n",
      "       <num>     <num>             <num>            <num>        <int>\n",
      "1: 0.3479526  182.8807          0.245025        0.7787628          740\n",
      "   min_sum_hessian_in_leaf\n",
      "                     <num>\n",
      "1:                   9.102\n",
      "[1] 0.9273942\n"
     ]
    }
   ],
   "source": [
    "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
    "print(PARAM$out$lgbm$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKsVZmAnhwX-"
   },
   "source": [
    "## 2.3  Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ_C33Tr5B_9"
   },
   "source": [
    "### Final Training\n",
    "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "eDqfyA14hzwv"
   },
   "outputs": [],
   "source": [
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento <- paste0(\"exp\", PARAM$experimento)\n",
    "dir.create(experimento, showWarnings= FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qFmFivf5Iet"
   },
   "source": [
    "#### Final Training Dataset\n",
    "\n",
    "Aqui esta la gran decision de en qué meses hago el Final Training\n",
    "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "lg5WVZncvc7H"
   },
   "outputs": [],
   "source": [
    "# clase01\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "yc9QzXREv0xf"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "thjdqEBLuvNt"
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[, clase01]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNUa-WSz5Oqu"
   },
   "source": [
    "#### Final Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "FgCcvBfEwImu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$boosting</dt>\n",
       "\t\t<dd>'gbdt'</dd>\n",
       "\t<dt>$objective</dt>\n",
       "\t\t<dd>'binary'</dd>\n",
       "\t<dt>$metric</dt>\n",
       "\t\t<dd>'auc'</dd>\n",
       "\t<dt>$first_metric_only</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$boost_from_average</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$feature_pre_filter</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$force_row_wise</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$verbosity</dt>\n",
       "\t\t<dd>-100</dd>\n",
       "\t<dt>$seed</dt>\n",
       "\t\t<dd>100379</dd>\n",
       "\t<dt>$max_depth</dt>\n",
       "\t\t<dd>-1</dd>\n",
       "\t<dt>$min_gain_to_split</dt>\n",
       "\t\t<dd>0.245025004925302</dd>\n",
       "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
       "\t\t<dd>9.10200044118497</dd>\n",
       "\t<dt>$lambda_l1</dt>\n",
       "\t\t<dd>0.34795257935396</dd>\n",
       "\t<dt>$lambda_l2</dt>\n",
       "\t\t<dd>182.880676556572</dd>\n",
       "\t<dt>$max_bin</dt>\n",
       "\t\t<dd>31</dd>\n",
       "\t<dt>$bagging_fraction</dt>\n",
       "\t\t<dd>0.778762848677653</dd>\n",
       "\t<dt>$pos_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$neg_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$is_unbalance</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$scale_pos_weight</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$drop_rate</dt>\n",
       "\t\t<dd>0.1</dd>\n",
       "\t<dt>$max_drop</dt>\n",
       "\t\t<dd>50</dd>\n",
       "\t<dt>$skip_drop</dt>\n",
       "\t\t<dd>0.5</dd>\n",
       "\t<dt>$extra_trees</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$num_iterations</dt>\n",
       "\t\t<dd>902</dd>\n",
       "\t<dt>$learning_rate</dt>\n",
       "\t\t<dd>0.0928760890926693</dd>\n",
       "\t<dt>$feature_fraction</dt>\n",
       "\t\t<dd>0.264631255046097</dd>\n",
       "\t<dt>$num_leaves</dt>\n",
       "\t\t<dd>1886</dd>\n",
       "\t<dt>$min_data_in_leaf</dt>\n",
       "\t\t<dd>598</dd>\n",
       "\t<dt>$bagging_freq</dt>\n",
       "\t\t<dd>740</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$boosting] 'gbdt'\n",
       "\\item[\\$objective] 'binary'\n",
       "\\item[\\$metric] 'auc'\n",
       "\\item[\\$first\\_metric\\_only] FALSE\n",
       "\\item[\\$boost\\_from\\_average] TRUE\n",
       "\\item[\\$feature\\_pre\\_filter] FALSE\n",
       "\\item[\\$force\\_row\\_wise] TRUE\n",
       "\\item[\\$verbosity] -100\n",
       "\\item[\\$seed] 100379\n",
       "\\item[\\$max\\_depth] -1\n",
       "\\item[\\$min\\_gain\\_to\\_split] 0.245025004925302\n",
       "\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 9.10200044118497\n",
       "\\item[\\$lambda\\_l1] 0.34795257935396\n",
       "\\item[\\$lambda\\_l2] 182.880676556572\n",
       "\\item[\\$max\\_bin] 31\n",
       "\\item[\\$bagging\\_fraction] 0.778762848677653\n",
       "\\item[\\$pos\\_bagging\\_fraction] 1\n",
       "\\item[\\$neg\\_bagging\\_fraction] 1\n",
       "\\item[\\$is\\_unbalance] FALSE\n",
       "\\item[\\$scale\\_pos\\_weight] 1\n",
       "\\item[\\$drop\\_rate] 0.1\n",
       "\\item[\\$max\\_drop] 50\n",
       "\\item[\\$skip\\_drop] 0.5\n",
       "\\item[\\$extra\\_trees] FALSE\n",
       "\\item[\\$num\\_iterations] 902\n",
       "\\item[\\$learning\\_rate] 0.0928760890926693\n",
       "\\item[\\$feature\\_fraction] 0.264631255046097\n",
       "\\item[\\$num\\_leaves] 1886\n",
       "\\item[\\$min\\_data\\_in\\_leaf] 598\n",
       "\\item[\\$bagging\\_freq] 740\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$boosting\n",
       ":   'gbdt'\n",
       "$objective\n",
       ":   'binary'\n",
       "$metric\n",
       ":   'auc'\n",
       "$first_metric_only\n",
       ":   FALSE\n",
       "$boost_from_average\n",
       ":   TRUE\n",
       "$feature_pre_filter\n",
       ":   FALSE\n",
       "$force_row_wise\n",
       ":   TRUE\n",
       "$verbosity\n",
       ":   -100\n",
       "$seed\n",
       ":   100379\n",
       "$max_depth\n",
       ":   -1\n",
       "$min_gain_to_split\n",
       ":   0.245025004925302\n",
       "$min_sum_hessian_in_leaf\n",
       ":   9.10200044118497\n",
       "$lambda_l1\n",
       ":   0.34795257935396\n",
       "$lambda_l2\n",
       ":   182.880676556572\n",
       "$max_bin\n",
       ":   31\n",
       "$bagging_fraction\n",
       ":   0.778762848677653\n",
       "$pos_bagging_fraction\n",
       ":   1\n",
       "$neg_bagging_fraction\n",
       ":   1\n",
       "$is_unbalance\n",
       ":   FALSE\n",
       "$scale_pos_weight\n",
       ":   1\n",
       "$drop_rate\n",
       ":   0.1\n",
       "$max_drop\n",
       ":   50\n",
       "$skip_drop\n",
       ":   0.5\n",
       "$extra_trees\n",
       ":   FALSE\n",
       "$num_iterations\n",
       ":   902\n",
       "$learning_rate\n",
       ":   0.0928760890926693\n",
       "$feature_fraction\n",
       ":   0.264631255046097\n",
       "$num_leaves\n",
       ":   1886\n",
       "$min_data_in_leaf\n",
       ":   598\n",
       "$bagging_freq\n",
       ":   740\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$boosting\n",
       "[1] \"gbdt\"\n",
       "\n",
       "$objective\n",
       "[1] \"binary\"\n",
       "\n",
       "$metric\n",
       "[1] \"auc\"\n",
       "\n",
       "$first_metric_only\n",
       "[1] FALSE\n",
       "\n",
       "$boost_from_average\n",
       "[1] TRUE\n",
       "\n",
       "$feature_pre_filter\n",
       "[1] FALSE\n",
       "\n",
       "$force_row_wise\n",
       "[1] TRUE\n",
       "\n",
       "$verbosity\n",
       "[1] -100\n",
       "\n",
       "$seed\n",
       "[1] 100379\n",
       "\n",
       "$max_depth\n",
       "[1] -1\n",
       "\n",
       "$min_gain_to_split\n",
       "[1] 0.245025\n",
       "\n",
       "$min_sum_hessian_in_leaf\n",
       "[1] 9.102\n",
       "\n",
       "$lambda_l1\n",
       "[1] 0.3479526\n",
       "\n",
       "$lambda_l2\n",
       "[1] 182.8807\n",
       "\n",
       "$max_bin\n",
       "[1] 31\n",
       "\n",
       "$bagging_fraction\n",
       "[1] 0.7787628\n",
       "\n",
       "$pos_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$neg_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$is_unbalance\n",
       "[1] FALSE\n",
       "\n",
       "$scale_pos_weight\n",
       "[1] 1\n",
       "\n",
       "$drop_rate\n",
       "[1] 0.1\n",
       "\n",
       "$max_drop\n",
       "[1] 50\n",
       "\n",
       "$skip_drop\n",
       "[1] 0.5\n",
       "\n",
       "$extra_trees\n",
       "[1] FALSE\n",
       "\n",
       "$num_iterations\n",
       "[1] 902\n",
       "\n",
       "$learning_rate\n",
       "[1] 0.09287609\n",
       "\n",
       "$feature_fraction\n",
       "[1] 0.2646313\n",
       "\n",
       "$num_leaves\n",
       "[1] 1886\n",
       "\n",
       "$min_data_in_leaf\n",
       "[1] 598\n",
       "\n",
       "$bagging_freq\n",
       "[1] 740\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
    "  PARAM$out$lgbm$mejores_hiperparametros)\n",
    "\n",
    "param_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZIYn4l95TBH"
   },
   "source": [
    "#### Training\n",
    "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "vPLsd4mMRe4u"
   },
   "outputs": [],
   "source": [
    "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
    "\n",
    "param_normalizado <- copy(param_final)\n",
    "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "WRI_-taRwOXO"
   },
   "outputs": [],
   "source": [
    "  # entreno LightGBM\n",
    "\n",
    "  modelo_final <- lgb.train(\n",
    "    data= dtrain,\n",
    "    param= param_normalizado\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "_bkhnCvj0g3Q"
   },
   "outputs": [],
   "source": [
    "# ahora imprimo la importancia de variables\n",
    "\n",
    "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
    "archivo_importancia <- \"impo.txt\"\n",
    "\n",
    "fwrite(tb_importancia,\n",
    "  file= archivo_importancia,\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lZ3sLmbh0kFj"
   },
   "outputs": [],
   "source": [
    "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
    "\n",
    "lgb.save(modelo_final, \"modelo.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEtp2--t5Ymg"
   },
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI5008Mj5ZdI"
   },
   "source": [
    "Aplico el modelo final a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "PimBY3N_0ryP"
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes == 202109]\n",
    "\n",
    "# aplico el modelo a los datos nuevos\n",
    "prediccion <- predict(\n",
    "  modelo_final,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D26rNRh55gpw"
   },
   "source": [
    "#### Tabla Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "RJwg7LHd11yu"
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "Kaggle Competition Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "gWW3tatE12je"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
      "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
      "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
      "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
      "Successfully submitted to Data Mining, Analista Sr 2025 B \n"
     ]
    }
   ],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "# suba TODOS los archivos a Kaggle\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "dir.create(\"kaggle\")\n",
    "\n",
    "for (envios in PARAM$kaggle$cortes) {\n",
    "\n",
    "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
    "\n",
    "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "    file= archivo_kaggle,\n",
    "    sep= \",\"\n",
    "  )\n",
    "\n",
    "  # subida a Kaggle, armo la linea de comando\n",
    "  comando <- \"kaggle competitions submit\"\n",
    "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
    "  arch <- paste( \"-f\", archivo_kaggle)\n",
    "\n",
    "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
    "  \"  semilla=\", PARAM$semilla_primigenia,\n",
    "    \"'\" )\n",
    "\n",
    "  linea <- paste( comando, competencia, arch, mensaje)\n",
    "\n",
    "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
    "  cat(salida, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "B9tB2X4439Hg"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "9zA_W25c15DP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Mon Sep 08 00:39:53 2025'"
      ],
      "text/latex": [
       "'Mon Sep 08 00:39:53 2025'"
      ],
      "text/markdown": [
       "'Mon Sep 08 00:39:53 2025'"
      ],
      "text/plain": [
       "[1] \"Mon Sep 08 00:39:53 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdVZucdLHzZ0"
   },
   "source": [
    "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
    "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
