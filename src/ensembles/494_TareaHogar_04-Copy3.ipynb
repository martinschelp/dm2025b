{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cEmzeUKFkPh"
   },
   "source": [
    "# Tarea para el Hogar 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSICPpyTGQmC"
   },
   "source": [
    "Esta Tarea para el Hogar 02 se entrega el final de la cuarta clase\n",
    "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 05 que será el miercoles 03 de septiembre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DenyKXkiJ5JN"
   },
   "source": [
    "##  1. Cazatalentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-K2_ZsZGrVD"
   },
   "source": [
    "En la Clase 03 nos hemos enfrentado a  \"La Maldicion del Ganandor\",  elegir el modelo con el mejor puntaje simple no suele ser la mejor estrategia.\n",
    "<br> Lea y ejecute el notebook  **src/CazaTalentos/CazaTalentos.ipynb**\n",
    "<br> en caso de interesarle, participe del Desafío Ordenamiento  que vence el sábado 06 de septiembre a las 19:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9GkTOk5J9t3"
   },
   "source": [
    "## 2. Hiperparámetros del LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmEFy0ukKL5T"
   },
   "source": [
    "Los objetivos de esta tarea son:\n",
    "\n",
    "\n",
    "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
    "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
    "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
    "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
    "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
    "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yvlS6JQLRMd"
   },
   "source": [
    "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
    "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eydI4YNAsFaf"
   },
   "source": [
    "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
    "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzU4S0SeMcpp"
   },
   "source": [
    "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
    "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
    "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNptUgI_NWWG"
   },
   "source": [
    "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
    "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
    "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
    "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
    "\n",
    "\n",
    "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
    "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpUThBojODyK"
   },
   "source": [
    "El desafío de esta tarea es:\n",
    "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
    "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
    "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX0qg_c0yqob"
   },
   "source": [
    "#### 2.1  Seteo del ambiente en Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGY7H9xza7Zr"
   },
   "source": [
    "Esta parte se debe correr con el runtime en Python3\n",
    "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PupIBNba7Zr"
   },
   "source": [
    "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LpZCst5a7Zs"
   },
   "outputs": [],
   "source": [
    "# primero establecer el Runtime de Python 3\n",
    "from google.colab import drive\n",
    "drive.mount('/content/.drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYC_F-wla7Zs"
   },
   "source": [
    "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
    "\n",
    "<br>los siguientes comando estan en shell script de Linux\n",
    "*   Crear las carpetas en el Google Drive\n",
    "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
    "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWLelftXa7Zt"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "mkdir -p \"/content/.drive/My Drive/dm\"\n",
    "mkdir -p \"/content/buckets\"\n",
    "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
    "\n",
    "mkdir -p ~/.kaggle\n",
    "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
    "chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "\n",
    "mkdir -p /content/buckets/b1/exp\n",
    "mkdir -p /content/buckets/b1/datasets\n",
    "mkdir -p /content/datasets\n",
    "\n",
    "\n",
    "\n",
    "archivo_origen=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/dataset_pequeno.csv\"\n",
    "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
    "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
    "\n",
    "if ! test -f $archivo_destino_bucket; then\n",
    "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
    "fi\n",
    "\n",
    "\n",
    "if ! test -f $archivo_destino; then\n",
    "  cp  $archivo_destino_bucket  $archivo_destino\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### 2.2 Optimizacion Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kwPpHAtSmix"
   },
   "source": [
    "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp4-Bj3aYI8d"
   },
   "source": [
    "### 2.2.1 Inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy8YTZfESxeJ"
   },
   "source": [
    "limpio el ambiente de R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gBq__iAdQliq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Wed Sep 03 01:29:52 2025'"
      ],
      "text/latex": [
       "'Wed Sep 03 01:29:52 2025'"
      ],
      "text/markdown": [
       "'Wed Sep 03 01:29:52 2025'"
      ],
      "text/plain": [
       "[1] \"Wed Sep 03 01:29:52 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7rdVrBojS1IV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 656930</td><td>35.1</td><td>1439371</td><td>76.9</td><td>1431354</td><td>76.5</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1224919</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1924961</td><td>14.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  656930 & 35.1 & 1439371 & 76.9 & 1431354 & 76.5\\\\\n",
       "\tVcells & 1224919 &  9.4 & 8388608 & 64.0 & 1924961 & 14.7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  656930 | 35.1 | 1439371 | 76.9 | 1431354 | 76.5 |\n",
       "| Vcells | 1224919 |  9.4 | 8388608 | 64.0 | 1924961 | 14.7 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  656930 35.1 1439371    76.9 1431354  76.5\n",
       "Vcells 1224919  9.4 8388608    64.0 1924961  14.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuPfQ7ksjwW3"
   },
   "source": [
    "### 2.2.2 Carga de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lVyxLaJ1j1J_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: primes\n",
      "\n",
      "Loading required package: rlist\n",
      "\n",
      "Loading required package: yaml\n",
      "\n",
      "Loading required package: lightgbm\n",
      "\n",
      "Loading required package: DiceKriging\n",
      "\n",
      "Loading required package: mlrMBO\n",
      "\n",
      "Loading required package: mlr\n",
      "\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "Loading required package: smoof\n",
      "\n",
      "Loading required package: checkmate\n",
      "\n",
      "\n",
      "Attaching package: ‘checkmate’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:DiceKriging’:\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cargo las librerias que necesito\n",
    "require(\"data.table\")\n",
    "require(\"parallel\")\n",
    "\n",
    "if( !require(\"primes\") ) install.packages(\"primes\")\n",
    "require(\"primes\")\n",
    "\n",
    "if( !require(\"utils\") ) install.packages(\"utils\")\n",
    "require(\"utils\")\n",
    "\n",
    "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
    "require(\"rlist\")\n",
    "\n",
    "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
    "require(\"yaml\")\n",
    "\n",
    "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")\n",
    "\n",
    "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz-6Qt6BUaA3"
   },
   "source": [
    "### 2.2.3 Definicion de Parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOdlKd7lUm2I"
   },
   "source": [
    "aqui debe cargar SU semilla primigenia\n",
    "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ASYkebOu2mF6"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- 4943\n",
    "PARAM$semilla_primigenia <- 100379\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ezOhQdbA293o"
   },
   "outputs": [],
   "source": [
    "PARAM$kaggle$competencia <- \"data-mining-analista-sr-2025-b\"\n",
    "PARAM$kaggle$cortes <- seq(10000, 12000, by= 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jtB0Lub42rHO"
   },
   "outputs": [],
   "source": [
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "# undersampling de 1.0  implica tomar TODOS los datos\n",
    "\n",
    "PARAM$trainingstrategy$undersampling <- 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OFxm-xiNUOJX"
   },
   "outputs": [],
   "source": [
    "# Parametros LightGBM\n",
    "\n",
    "PARAM$hyperparametertuning$xval_folds <- 5\n",
    "\n",
    "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
    "PARAM$lgbm$param_fijos <-  list(\n",
    "  boosting= \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
    "  objective= \"binary\",\n",
    "  metric= \"auc\",\n",
    "  first_metric_only= FALSE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  force_row_wise= TRUE, # para reducir warnings\n",
    "  verbosity= -100,\n",
    "\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "\n",
    "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
    "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1= 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2= 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
    "\n",
    "  bagging_fraction= 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance= FALSE, #\n",
    "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop= 50, # <=0 means no limit\n",
    "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees= FALSE,\n",
    "\n",
    "  num_iterations= 792,\n",
    "  learning_rate= 0.0126426,\n",
    "  feature_fraction= 0.3175726,\n",
    "  num_leaves= 800,\n",
    "  min_data_in_leaf= 957\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5Yj-JV4yvOt"
   },
   "source": [
    "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
    "<br> si es un numero entero debe ir  makeIntegerParam\n",
    "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
    "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jENpR26ZyuS8"
   },
   "outputs": [],
   "source": [
    "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
    "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
    "  makeIntegerParam(\"num_iterations\", lower= 8L, upper= 2048L),\n",
    "  makeNumericParam(\"learning_rate\", lower= 0.001, upper= 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower= 0.01, upper= 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower= 8L, upper= 2048L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower= 1L, upper= 4000L),\n",
    "    makeIntegerParam(\"min_gain_to_split\", lower=0L, upper=5L),\n",
    "    makeNumericParam(\"min_sum_hessian_in_leaf\", lower= 0.001, upper= 10),\n",
    "    makeIntegerParam(\"max_depth\", lower= -1L, upper= 15L),\n",
    "    makeNumericParam(\"bagging_fraction\", lower= 0.5, upper= 1),\n",
    "    makeNumericParam(\"lambda_l1\", lower = 0.0, upper = 5.0),\n",
    "    makeNumericParam(\"lambda_l2\", lower = 0.0, upper = 5.0),\n",
    "    makeNumericParam(\"scale_pos_weight\", lower = 1.0, upper = 100.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_RPFUb3zMoW"
   },
   "source": [
    "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
    "<br> 30 es un valor muy tacaño, pero corre rápido\n",
    "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "q5Rd3pnbzSiG"
   },
   "outputs": [],
   "source": [
    "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RWZXL1VZjMI"
   },
   "source": [
    "### 2.2.4  Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "j3toG9-lZm4K"
   },
   "outputs": [],
   "source": [
    "# carpeta de trabajo\n",
    "\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FM3lxKoLZ643"
   },
   "outputs": [],
   "source": [
    "# lectura del dataset\n",
    "\n",
    "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OsJ-91UeZ-I_"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vrWE7BE0aB2J"
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "\n",
    "dataset_train[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jP7YlQBnaW6W"
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "# notar que para esto utilizo la SEGUNDA semilla\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train[, azar := runif(nrow(dataset_train))]\n",
    "dataset_train[, training := 0L]\n",
    "\n",
    "dataset_train[\n",
    "  foto_mes %in% c(202107) &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xElu4s5W4rX7"
   },
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PppMHcGYaaol"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "83507"
      ],
      "text/latex": [
       "83507"
      ],
      "text/markdown": [
       "83507"
      ],
      "text/plain": [
       "[1] 83507"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "154"
      ],
      "text/latex": [
       "154"
      ],
      "text/markdown": [
       "154"
      ],
      "text/plain": [
       "[1] 154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "nrow(dtrain)\n",
    "ncol(dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta-EkOu3cphF"
   },
   "source": [
    "2.2.5 Configuracion Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cjgfurjdfiXb"
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la AUC en cross validation del modelo entrenado\n",
    "\n",
    "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  # entreno LightGBM\n",
    "  modelocv <- lgb.cv(\n",
    "    data= dtrain,\n",
    "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
    "    stratified= TRUE,\n",
    "    param= param_completo\n",
    "  )\n",
    "\n",
    "  # obtengo la ganancia\n",
    "  AUC <- modelocv$best_score\n",
    "\n",
    "  # hago espacio en la memoria\n",
    "  rm(modelocv)\n",
    "  gc(full= TRUE, verbose= FALSE)\n",
    "\n",
    "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
    "\n",
    "  return(AUC)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "WLi_o1hocvN-"
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "\n",
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "kbayesiana <- \"bayesiana.RDATA\"\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hyperparametertuning$iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uUeVo5pc4zc"
   },
   "source": [
    "2.2.6 Corrida Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RcABNaKGciaz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing y column(s) for design. Not provided.\n",
      "\n",
      "Wed Sep 03 01:31:11 2025 AUC 0.920410876007279\n",
      "\n",
      "Wed Sep 03 01:31:47 2025 AUC 0.923885151623727\n",
      "\n",
      "Wed Sep 03 01:32:08 2025 AUC 0.925358382981919\n",
      "\n",
      "Wed Sep 03 01:32:33 2025 AUC 0.924856567266135\n",
      "\n",
      "Wed Sep 03 01:32:50 2025 AUC 0.912912895092827\n",
      "\n",
      "Wed Sep 03 01:33:03 2025 AUC 0.91961100391844\n",
      "\n",
      "Wed Sep 03 01:34:15 2025 AUC 0.921669137164117\n",
      "\n",
      "Wed Sep 03 01:34:35 2025 AUC 0.920850644617635\n",
      "\n",
      "Wed Sep 03 01:35:20 2025 AUC 0.92499689814714\n",
      "\n",
      "Wed Sep 03 01:35:56 2025 AUC 0.922221993123939\n",
      "\n",
      "Wed Sep 03 01:35:59 2025 AUC 0.919785596870068\n",
      "\n",
      "Wed Sep 03 01:37:13 2025 AUC 0.923351240896727\n",
      "\n",
      "Wed Sep 03 01:38:03 2025 AUC 0.915910017312065\n",
      "\n",
      "Wed Sep 03 01:39:01 2025 AUC 0.918655081268253\n",
      "\n",
      "Wed Sep 03 01:39:19 2025 AUC 0.923080894637984\n",
      "\n",
      "Wed Sep 03 01:39:26 2025 AUC 0.924028472326255\n",
      "\n",
      "Wed Sep 03 01:39:36 2025 AUC 0.915427083148456\n",
      "\n",
      "Wed Sep 03 01:39:52 2025 AUC 0.911876022715779\n",
      "\n",
      "Wed Sep 03 01:40:12 2025 AUC 0.910789213642232\n",
      "\n",
      "Wed Sep 03 01:41:13 2025 AUC 0.916462133323141\n",
      "\n",
      "Wed Sep 03 01:41:49 2025 AUC 0.921774575619421\n",
      "\n",
      "Wed Sep 03 01:43:29 2025 AUC 0.924709795101085\n",
      "\n",
      "Wed Sep 03 01:44:36 2025 AUC 0.923662541219717\n",
      "\n",
      "Wed Sep 03 01:44:52 2025 AUC 0.917500509676444\n",
      "\n",
      "Wed Sep 03 01:45:51 2025 AUC 0.92039962448897\n",
      "\n",
      "Wed Sep 03 01:46:33 2025 AUC 0.926753260815159\n",
      "\n",
      "Wed Sep 03 01:46:37 2025 AUC 0.922099406056022\n",
      "\n",
      "Wed Sep 03 01:46:54 2025 AUC 0.921075234582638\n",
      "\n",
      "Wed Sep 03 01:47:17 2025 AUC 0.922146248006222\n",
      "\n",
      "Wed Sep 03 01:47:35 2025 AUC 0.923337390353711\n",
      "\n",
      "Wed Sep 03 01:48:08 2025 AUC 0.927343557979561\n",
      "\n",
      "Wed Sep 03 01:48:37 2025 AUC 0.919706858054354\n",
      "\n",
      "Wed Sep 03 01:49:28 2025 AUC 0.920146477212912\n",
      "\n",
      "Wed Sep 03 01:50:38 2025 AUC 0.918821544383962\n",
      "\n",
      "Wed Sep 03 01:51:02 2025 AUC 0.923007576998373\n",
      "\n",
      "Wed Sep 03 01:51:09 2025 AUC 0.912494594643598\n",
      "\n",
      "Wed Sep 03 01:51:12 2025 AUC 0.904040960666722\n",
      "\n",
      "Wed Sep 03 01:52:07 2025 AUC 0.916434936329325\n",
      "\n",
      "Wed Sep 03 01:52:35 2025 AUC 0.926159368536149\n",
      "\n",
      "Wed Sep 03 01:52:49 2025 AUC 0.92283605925994\n",
      "\n",
      "Wed Sep 03 01:54:04 2025 AUC 0.924185816528679\n",
      "\n",
      "Wed Sep 03 01:55:09 2025 AUC 0.915433002081534\n",
      "\n",
      "Wed Sep 03 01:55:20 2025 AUC 0.920679341240249\n",
      "\n",
      "Wed Sep 03 01:55:45 2025 AUC 0.908113831508735\n",
      "\n",
      "Wed Sep 03 01:55:55 2025 AUC 0.909969027552423\n",
      "\n",
      "Wed Sep 03 01:56:13 2025 AUC 0.915876898549324\n",
      "\n",
      "Wed Sep 03 01:56:54 2025 AUC 0.926911178538366\n",
      "\n",
      "Wed Sep 03 01:59:15 2025 AUC 0.926083395524278\n",
      "\n",
      "[mbo] 3: num_iterations=1426; learning_rate=0.0223; feature_fraction=0.865; num_leaves=923; min_data_in_leaf=2209; min_gain_to_split=3; min_sum_hessian_in_leaf=6.51; max_depth=13; bagging_fraction=0.858; lambda_l1=2.29; lambda_l2=0.679; scale_pos_weight=39.5 : y = 0.926 : 40.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 01:59:50 2025 AUC 0.925597062819115\n",
      "\n",
      "[mbo] 4: num_iterations=1037; learning_rate=0.028; feature_fraction=0.827; num_leaves=888; min_data_in_leaf=3055; min_gain_to_split=0; min_sum_hessian_in_leaf=3.74; max_depth=10; bagging_fraction=0.95; lambda_l1=1.5; lambda_l2=1.43; scale_pos_weight=43.9 : y = 0.926 : 33.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:00:33 2025 AUC 0.929331364814927\n",
      "\n",
      "[mbo] 5: num_iterations=925; learning_rate=0.0424; feature_fraction=0.629; num_leaves=1068; min_data_in_leaf=870; min_gain_to_split=2; min_sum_hessian_in_leaf=3.72; max_depth=14; bagging_fraction=0.843; lambda_l1=2.38; lambda_l2=0.498; scale_pos_weight=35.9 : y = 0.929 : 41.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:01:12 2025 AUC 0.928245597890926\n",
      "\n",
      "[mbo] 6: num_iterations=1259; learning_rate=0.0429; feature_fraction=0.618; num_leaves=1239; min_data_in_leaf=569; min_gain_to_split=2; min_sum_hessian_in_leaf=1.62; max_depth=11; bagging_fraction=0.756; lambda_l1=3.59; lambda_l2=0.145; scale_pos_weight=19.7 : y = 0.928 : 36.9 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:01:50 2025 AUC 0.927387370780307\n",
      "\n",
      "[mbo] 7: num_iterations=913; learning_rate=0.0456; feature_fraction=0.618; num_leaves=1208; min_data_in_leaf=402; min_gain_to_split=2; min_sum_hessian_in_leaf=5.8; max_depth=15; bagging_fraction=0.9; lambda_l1=4.15; lambda_l2=0.583; scale_pos_weight=91.4 : y = 0.927 : 36.5 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:02:36 2025 AUC 0.926723367046204\n",
      "\n",
      "[mbo] 8: num_iterations=1333; learning_rate=0.0653; feature_fraction=0.626; num_leaves=1121; min_data_in_leaf=823; min_gain_to_split=2; min_sum_hessian_in_leaf=3.56; max_depth=11; bagging_fraction=0.807; lambda_l1=1.21; lambda_l2=1.6; scale_pos_weight=37.1 : y = 0.927 : 43.4 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:02:58 2025 AUC 0.926571134780436\n",
      "\n",
      "[mbo] 9: num_iterations=919; learning_rate=0.0358; feature_fraction=0.654; num_leaves=1116; min_data_in_leaf=949; min_gain_to_split=2; min_sum_hessian_in_leaf=2.68; max_depth=3; bagging_fraction=0.758; lambda_l1=2.78; lambda_l2=0.0713; scale_pos_weight=17 : y = 0.927 : 20.1 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:03:49 2025 AUC 0.927286058589736\n",
      "\n",
      "[mbo] 10: num_iterations=1018; learning_rate=0.0296; feature_fraction=0.608; num_leaves=500; min_data_in_leaf=2091; min_gain_to_split=1; min_sum_hessian_in_leaf=4.51; max_depth=15; bagging_fraction=0.761; lambda_l1=3.5; lambda_l2=0.395; scale_pos_weight=33.8 : y = 0.927 : 49.4 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:04:30 2025 AUC 0.926595883476524\n",
      "\n",
      "[mbo] 11: num_iterations=932; learning_rate=0.0461; feature_fraction=0.646; num_leaves=1463; min_data_in_leaf=261; min_gain_to_split=2; min_sum_hessian_in_leaf=1.17; max_depth=15; bagging_fraction=0.786; lambda_l1=2.41; lambda_l2=0.82; scale_pos_weight=51.2 : y = 0.927 : 38.4 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:05:06 2025 AUC 0.927413679996425\n",
      "\n",
      "[mbo] 12: num_iterations=1080; learning_rate=0.0437; feature_fraction=0.645; num_leaves=495; min_data_in_leaf=1022; min_gain_to_split=3; min_sum_hessian_in_leaf=3.96; max_depth=15; bagging_fraction=0.952; lambda_l1=4.05; lambda_l2=0.0648; scale_pos_weight=45.5 : y = 0.927 : 33.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:06:09 2025 AUC 0.92770086451151\n",
      "\n",
      "[mbo] 13: num_iterations=1351; learning_rate=0.0419; feature_fraction=0.564; num_leaves=1086; min_data_in_leaf=1614; min_gain_to_split=2; min_sum_hessian_in_leaf=4.23; max_depth=13; bagging_fraction=0.89; lambda_l1=2.77; lambda_l2=0.987; scale_pos_weight=19.6 : y = 0.928 : 61.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:06:53 2025 AUC 0.926899874752785\n",
      "\n",
      "[mbo] 14: num_iterations=1099; learning_rate=0.0398; feature_fraction=0.617; num_leaves=1038; min_data_in_leaf=952; min_gain_to_split=2; min_sum_hessian_in_leaf=4.59; max_depth=15; bagging_fraction=0.642; lambda_l1=3.27; lambda_l2=2.8; scale_pos_weight=58.7 : y = 0.927 : 42.4 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:07:53 2025 AUC 0.9295795720551\n",
      "\n",
      "[mbo] 15: num_iterations=903; learning_rate=0.0406; feature_fraction=0.692; num_leaves=619; min_data_in_leaf=782; min_gain_to_split=0; min_sum_hessian_in_leaf=8.13; max_depth=15; bagging_fraction=0.877; lambda_l1=3.02; lambda_l2=1.69; scale_pos_weight=13.6 : y = 0.93 : 57.8 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 16 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Sep 03 02:08:29 2025 AUC 0.927991556974945\n",
      "\n",
      "[mbo] 16: num_iterations=914; learning_rate=0.0455; feature_fraction=0.621; num_leaves=776; min_data_in_leaf=802; min_gain_to_split=1; min_sum_hessian_in_leaf=7.22; max_depth=15; bagging_fraction=0.86; lambda_l1=2.71; lambda_l2=0.364; scale_pos_weight=18.5 : y = 0.928 : 30.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:08:56 2025 AUC 0.929056507776139\n",
      "\n",
      "[mbo] 17: num_iterations=879; learning_rate=0.0346; feature_fraction=0.748; num_leaves=316; min_data_in_leaf=420; min_gain_to_split=2; min_sum_hessian_in_leaf=5.99; max_depth=11; bagging_fraction=0.746; lambda_l1=2.89; lambda_l2=3.37; scale_pos_weight=12.3 : y = 0.929 : 24.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:10:25 2025 AUC 0.929103219508806\n",
      "\n",
      "[mbo] 18: num_iterations=1251; learning_rate=0.0309; feature_fraction=0.757; num_leaves=442; min_data_in_leaf=456; min_gain_to_split=0; min_sum_hessian_in_leaf=3.44; max_depth=13; bagging_fraction=0.883; lambda_l1=3.13; lambda_l2=2.58; scale_pos_weight=23.3 : y = 0.929 : 87.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:10:58 2025 AUC 0.928677057999005\n",
      "\n",
      "[mbo] 19: num_iterations=893; learning_rate=0.0323; feature_fraction=0.695; num_leaves=907; min_data_in_leaf=834; min_gain_to_split=2; min_sum_hessian_in_leaf=2.84; max_depth=12; bagging_fraction=0.911; lambda_l1=2.82; lambda_l2=1.87; scale_pos_weight=25.6 : y = 0.929 : 31.1 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:11:39 2025 AUC 0.929427309108243\n",
      "\n",
      "[mbo] 20: num_iterations=470; learning_rate=0.0374; feature_fraction=0.734; num_leaves=980; min_data_in_leaf=369; min_gain_to_split=0; min_sum_hessian_in_leaf=5.01; max_depth=15; bagging_fraction=0.867; lambda_l1=3.1; lambda_l2=0.982; scale_pos_weight=6.59 : y = 0.929 : 38.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:13:23 2025 AUC 0.927655341278402\n",
      "\n",
      "[mbo] 21: num_iterations=1655; learning_rate=0.0356; feature_fraction=0.75; num_leaves=280; min_data_in_leaf=317; min_gain_to_split=0; min_sum_hessian_in_leaf=9.62; max_depth=11; bagging_fraction=0.779; lambda_l1=1.38; lambda_l2=1.74; scale_pos_weight=27.6 : y = 0.928 : 101.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:13:58 2025 AUC 0.927676251542432\n",
      "\n",
      "[mbo] 22: num_iterations=808; learning_rate=0.0374; feature_fraction=0.743; num_leaves=1003; min_data_in_leaf=10; min_gain_to_split=1; min_sum_hessian_in_leaf=8.86; max_depth=10; bagging_fraction=0.74; lambda_l1=3.98; lambda_l2=1.76; scale_pos_weight=14.8 : y = 0.928 : 33.3 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:16:25 2025 AUC 0.928873977087755\n",
      "\n",
      "[mbo] 24: num_iterations=1491; learning_rate=0.0334; feature_fraction=0.702; num_leaves=218; min_data_in_leaf=423; min_gain_to_split=0; min_sum_hessian_in_leaf=3.52; max_depth=12; bagging_fraction=0.837; lambda_l1=1.61; lambda_l2=0.499; scale_pos_weight=6.4 : y = 0.929 : 94.5 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:17:12 2025 AUC 0.929143575076432\n",
      "\n",
      "[mbo] 25: num_iterations=687; learning_rate=0.0358; feature_fraction=0.719; num_leaves=379; min_data_in_leaf=487; min_gain_to_split=0; min_sum_hessian_in_leaf=6.07; max_depth=13; bagging_fraction=0.957; lambda_l1=2.99; lambda_l2=3.73; scale_pos_weight=53.7 : y = 0.929 : 44.3 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:17:38 2025 AUC 0.929499963869827\n",
      "\n",
      "[mbo] 26: num_iterations=877; learning_rate=0.0347; feature_fraction=0.728; num_leaves=429; min_data_in_leaf=423; min_gain_to_split=3; min_sum_hessian_in_leaf=3.55; max_depth=15; bagging_fraction=0.846; lambda_l1=1.53; lambda_l2=1.54; scale_pos_weight=15.8 : y = 0.929 : 24.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:18:12 2025 AUC 0.929319331824352\n",
      "\n",
      "[mbo] 27: num_iterations=926; learning_rate=0.036; feature_fraction=0.733; num_leaves=416; min_data_in_leaf=288; min_gain_to_split=1; min_sum_hessian_in_leaf=6.03; max_depth=15; bagging_fraction=0.905; lambda_l1=2.47; lambda_l2=2.72; scale_pos_weight=14.5 : y = 0.929 : 31.7 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 28 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Sep 03 02:19:05 2025 AUC 0.928177686709388\n",
      "\n",
      "[mbo] 28: num_iterations=730; learning_rate=0.0313; feature_fraction=0.748; num_leaves=306; min_data_in_leaf=609; min_gain_to_split=0; min_sum_hessian_in_leaf=4.56; max_depth=14; bagging_fraction=0.703; lambda_l1=1.48; lambda_l2=1.84; scale_pos_weight=69.2 : y = 0.928 : 47.4 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:20:19 2025 AUC 0.927636355398787\n",
      "\n",
      "[mbo] 29: num_iterations=1227; learning_rate=0.0391; feature_fraction=0.712; num_leaves=1094; min_data_in_leaf=922; min_gain_to_split=0; min_sum_hessian_in_leaf=4.42; max_depth=13; bagging_fraction=0.842; lambda_l1=1.59; lambda_l2=0.86; scale_pos_weight=14.3 : y = 0.928 : 71.7 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:21:02 2025 AUC 0.929115014174284\n",
      "\n",
      "[mbo] 30: num_iterations=518; learning_rate=0.033; feature_fraction=0.731; num_leaves=276; min_data_in_leaf=403; min_gain_to_split=0; min_sum_hessian_in_leaf=7.48; max_depth=15; bagging_fraction=0.907; lambda_l1=3.28; lambda_l2=1.99; scale_pos_weight=44.2 : y = 0.929 : 40.5 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:22:29 2025 AUC 0.927923577873156\n",
      "\n",
      "[mbo] 31: num_iterations=1221; learning_rate=0.039; feature_fraction=0.704; num_leaves=312; min_data_in_leaf=456; min_gain_to_split=0; min_sum_hessian_in_leaf=5.13; max_depth=13; bagging_fraction=0.835; lambda_l1=3.66; lambda_l2=1.66; scale_pos_weight=20.8 : y = 0.928 : 84.9 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:23:11 2025 AUC 0.928546699012378\n",
      "\n",
      "[mbo] 32: num_iterations=1827; learning_rate=0.031; feature_fraction=0.74; num_leaves=311; min_data_in_leaf=468; min_gain_to_split=4; min_sum_hessian_in_leaf=3.14; max_depth=12; bagging_fraction=0.792; lambda_l1=1.84; lambda_l2=1.11; scale_pos_weight=37.8 : y = 0.929 : 40.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:23:32 2025 AUC 0.927783534023339\n",
      "\n",
      "[mbo] 33: num_iterations=614; learning_rate=0.0406; feature_fraction=0.671; num_leaves=1031; min_data_in_leaf=1431; min_gain_to_split=3; min_sum_hessian_in_leaf=4.7; max_depth=15; bagging_fraction=0.824; lambda_l1=3.39; lambda_l2=1.27; scale_pos_weight=11.3 : y = 0.928 : 18.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:24:12 2025 AUC 0.927072069196373\n",
      "\n",
      "[mbo] 34: num_iterations=1363; learning_rate=0.0276; feature_fraction=0.661; num_leaves=534; min_data_in_leaf=73; min_gain_to_split=4; min_sum_hessian_in_leaf=3.14; max_depth=12; bagging_fraction=0.705; lambda_l1=2.04; lambda_l2=0.551; scale_pos_weight=20.8 : y = 0.927 : 36.9 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:24:40 2025 AUC 0.927789377367234\n",
      "\n",
      "[mbo] 35: num_iterations=1171; learning_rate=0.0422; feature_fraction=0.789; num_leaves=96; min_data_in_leaf=676; min_gain_to_split=4; min_sum_hessian_in_leaf=3.61; max_depth=9; bagging_fraction=0.905; lambda_l1=1.78; lambda_l2=0.872; scale_pos_weight=85.1 : y = 0.928 : 26.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:24:59 2025 AUC 0.930247885747082\n",
      "\n",
      "[mbo] 36: num_iterations=504; learning_rate=0.0323; feature_fraction=0.749; num_leaves=518; min_data_in_leaf=671; min_gain_to_split=2; min_sum_hessian_in_leaf=3.29; max_depth=14; bagging_fraction=0.919; lambda_l1=2.28; lambda_l2=0.208; scale_pos_weight=6.92 : y = 0.93 : 16.9 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:25:29 2025 AUC 0.929199431733651\n",
      "\n",
      "[mbo] 37: num_iterations=871; learning_rate=0.0203; feature_fraction=0.767; num_leaves=70; min_data_in_leaf=748; min_gain_to_split=2; min_sum_hessian_in_leaf=2.12; max_depth=15; bagging_fraction=0.82; lambda_l1=1.74; lambda_l2=0.553; scale_pos_weight=3.66 : y = 0.929 : 27.5 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:26:36 2025 AUC 0.926856458683649\n",
      "\n",
      "[mbo] 38: num_iterations=1475; learning_rate=0.0933; feature_fraction=0.465; num_leaves=1280; min_data_in_leaf=753; min_gain_to_split=3; min_sum_hessian_in_leaf=0.895; max_depth=10; bagging_fraction=0.864; lambda_l1=4.61; lambda_l2=1.41; scale_pos_weight=33 : y = 0.927 : 64.4 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:27:14 2025 AUC 0.927287311051037\n",
      "\n",
      "[mbo] 39: num_iterations=581; learning_rate=0.0282; feature_fraction=0.731; num_leaves=1343; min_data_in_leaf=577; min_gain_to_split=1; min_sum_hessian_in_leaf=9.83; max_depth=15; bagging_fraction=0.704; lambda_l1=2.85; lambda_l2=4.52; scale_pos_weight=67.8 : y = 0.927 : 35.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:27:34 2025 AUC 0.928705477241264\n",
      "\n",
      "[mbo] 40: num_iterations=595; learning_rate=0.0229; feature_fraction=0.755; num_leaves=540; min_data_in_leaf=491; min_gain_to_split=0; min_sum_hessian_in_leaf=8.85; max_depth=5; bagging_fraction=0.88; lambda_l1=2.61; lambda_l2=3.49; scale_pos_weight=11.5 : y = 0.929 : 17.3 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:28:23 2025 AUC 0.929362029084259\n",
      "\n",
      "[mbo] 41: num_iterations=780; learning_rate=0.0295; feature_fraction=0.753; num_leaves=468; min_data_in_leaf=705; min_gain_to_split=0; min_sum_hessian_in_leaf=9.56; max_depth=15; bagging_fraction=0.934; lambda_l1=1.78; lambda_l2=4.94; scale_pos_weight=23.6 : y = 0.929 : 47.0 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 42 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Sep 03 02:29:10 2025 AUC 0.930031601784465\n",
      "\n",
      "[mbo] 42: num_iterations=1679; learning_rate=0.0267; feature_fraction=0.793; num_leaves=22; min_data_in_leaf=774; min_gain_to_split=2; min_sum_hessian_in_leaf=2.92; max_depth=11; bagging_fraction=0.884; lambda_l1=2.15; lambda_l2=3.93; scale_pos_weight=11.6 : y = 0.93 : 40.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:29:44 2025 AUC 0.926651460704807\n",
      "\n",
      "[mbo] 43: num_iterations=578; learning_rate=0.0268; feature_fraction=0.869; num_leaves=230; min_data_in_leaf=333; min_gain_to_split=3; min_sum_hessian_in_leaf=3.49; max_depth=13; bagging_fraction=0.842; lambda_l1=1.76; lambda_l2=4.38; scale_pos_weight=56.8 : y = 0.927 : 30.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:33:31 2025 AUC 0.928266882993812\n",
      "\n",
      "[mbo] 47: num_iterations=1806; learning_rate=0.0214; feature_fraction=0.779; num_leaves=126; min_data_in_leaf=1080; min_gain_to_split=2; min_sum_hessian_in_leaf=3.1; max_depth=14; bagging_fraction=0.956; lambda_l1=0.249; lambda_l2=1.21; scale_pos_weight=13.7 : y = 0.928 : 46.7 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:34:21 2025 AUC 0.927117867522103\n",
      "\n",
      "[mbo] 48: num_iterations=1644; learning_rate=0.0295; feature_fraction=0.786; num_leaves=469; min_data_in_leaf=703; min_gain_to_split=2; min_sum_hessian_in_leaf=3.7; max_depth=9; bagging_fraction=0.899; lambda_l1=2.06; lambda_l2=3.37; scale_pos_weight=70.4 : y = 0.927 : 46.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:34:51 2025 AUC 0.927222576673992\n",
      "\n",
      "[mbo] 49: num_iterations=440; learning_rate=0.0402; feature_fraction=0.724; num_leaves=708; min_data_in_leaf=940; min_gain_to_split=0; min_sum_hessian_in_leaf=9.66; max_depth=14; bagging_fraction=0.913; lambda_l1=2.55; lambda_l2=0.551; scale_pos_weight=91.6 : y = 0.927 : 27.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:35:27 2025 AUC 0.929226452326354\n",
      "\n",
      "[mbo] 50: num_iterations=415; learning_rate=0.0282; feature_fraction=0.585; num_leaves=1388; min_data_in_leaf=552; min_gain_to_split=0; min_sum_hessian_in_leaf=3.34; max_depth=14; bagging_fraction=0.938; lambda_l1=3.81; lambda_l2=0.024; scale_pos_weight=7.19 : y = 0.929 : 33.3 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:36:18 2025 AUC 0.930061892468903\n",
      "\n",
      "[mbo] 51: num_iterations=834; learning_rate=0.0192; feature_fraction=0.741; num_leaves=345; min_data_in_leaf=836; min_gain_to_split=0; min_sum_hessian_in_leaf=8.96; max_depth=14; bagging_fraction=0.932; lambda_l1=2.18; lambda_l2=0.502; scale_pos_weight=4.58 : y = 0.93 : 48.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:37:01 2025 AUC 0.928105243941584\n",
      "\n",
      "[mbo] 52: num_iterations=909; learning_rate=0.0192; feature_fraction=0.732; num_leaves=238; min_data_in_leaf=1523; min_gain_to_split=0; min_sum_hessian_in_leaf=8.18; max_depth=14; bagging_fraction=0.875; lambda_l1=2.98; lambda_l2=4.81; scale_pos_weight=9.08 : y = 0.928 : 39.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:37:50 2025 AUC 0.929067632344682\n",
      "\n",
      "[mbo] 53: num_iterations=726; learning_rate=0.0275; feature_fraction=0.7; num_leaves=1546; min_data_in_leaf=722; min_gain_to_split=0; min_sum_hessian_in_leaf=9.68; max_depth=15; bagging_fraction=0.925; lambda_l1=3.43; lambda_l2=1.54; scale_pos_weight=20.4 : y = 0.929 : 46.4 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:38:13 2025 AUC 0.929014149450278\n",
      "\n",
      "[mbo] 54: num_iterations=1018; learning_rate=0.0314; feature_fraction=0.804; num_leaves=187; min_data_in_leaf=1185; min_gain_to_split=4; min_sum_hessian_in_leaf=8.99; max_depth=9; bagging_fraction=0.991; lambda_l1=3.1; lambda_l2=4.52; scale_pos_weight=6.87 : y = 0.929 : 19.9 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:38:50 2025 AUC 0.928946128271526\n",
      "\n",
      "[mbo] 55: num_iterations=1973; learning_rate=0.0265; feature_fraction=0.837; num_leaves=50; min_data_in_leaf=960; min_gain_to_split=5; min_sum_hessian_in_leaf=3.59; max_depth=11; bagging_fraction=0.96; lambda_l1=3.56; lambda_l2=4.37; scale_pos_weight=10.4 : y = 0.929 : 35.0 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 56 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Sep 03 02:39:36 2025 AUC 0.928571269588642\n",
      "\n",
      "[mbo] 56: num_iterations=1824; learning_rate=0.0233; feature_fraction=0.821; num_leaves=11; min_data_in_leaf=1007; min_gain_to_split=4; min_sum_hessian_in_leaf=8.82; max_depth=10; bagging_fraction=0.843; lambda_l1=2.2; lambda_l2=3.65; scale_pos_weight=20 : y = 0.929 : 38.3 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:40:42 2025 AUC 0.926631106179557\n",
      "\n",
      "[mbo] 57: num_iterations=846; learning_rate=0.0933; feature_fraction=0.433; num_leaves=1541; min_data_in_leaf=495; min_gain_to_split=0; min_sum_hessian_in_leaf=3.2; max_depth=9; bagging_fraction=0.81; lambda_l1=3.85; lambda_l2=4.86; scale_pos_weight=8.54 : y = 0.927 : 62.9 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:41:35 2025 AUC 0.929152201969292\n",
      "\n",
      "[mbo] 58: num_iterations=857; learning_rate=0.0268; feature_fraction=0.746; num_leaves=577; min_data_in_leaf=583; min_gain_to_split=0; min_sum_hessian_in_leaf=8.02; max_depth=14; bagging_fraction=0.978; lambda_l1=2.78; lambda_l2=1.99; scale_pos_weight=2.97 : y = 0.929 : 50.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:42:03 2025 AUC 0.928165588355546\n",
      "\n",
      "[mbo] 59: num_iterations=752; learning_rate=0.0308; feature_fraction=0.761; num_leaves=211; min_data_in_leaf=919; min_gain_to_split=3; min_sum_hessian_in_leaf=9.82; max_depth=12; bagging_fraction=0.91; lambda_l1=2.17; lambda_l2=0.574; scale_pos_weight=22.1 : y = 0.928 : 24.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:43:20 2025 AUC 0.926262934856748\n",
      "\n",
      "[mbo] 60: num_iterations=886; learning_rate=0.064; feature_fraction=0.589; num_leaves=1350; min_data_in_leaf=18; min_gain_to_split=0; min_sum_hessian_in_leaf=9.96; max_depth=14; bagging_fraction=0.665; lambda_l1=4.07; lambda_l2=4.37; scale_pos_weight=14 : y = 0.926 : 74.1 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:43:49 2025 AUC 0.929010563948466\n",
      "\n",
      "[mbo] 61: num_iterations=1578; learning_rate=0.0356; feature_fraction=0.833; num_leaves=11; min_data_in_leaf=774; min_gain_to_split=4; min_sum_hessian_in_leaf=3.61; max_depth=14; bagging_fraction=0.844; lambda_l1=2.17; lambda_l2=2.2; scale_pos_weight=3.04 : y = 0.929 : 25.9 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:44:32 2025 AUC 0.929311505974552\n",
      "\n",
      "[mbo] 62: num_iterations=1968; learning_rate=0.0314; feature_fraction=0.928; num_leaves=36; min_data_in_leaf=278; min_gain_to_split=2; min_sum_hessian_in_leaf=3.4; max_depth=9; bagging_fraction=0.9; lambda_l1=1.8; lambda_l2=4.73; scale_pos_weight=8.48 : y = 0.929 : 40.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:45:20 2025 AUC 0.9277239738274\n",
      "\n",
      "[mbo] 63: num_iterations=654; learning_rate=0.0406; feature_fraction=0.727; num_leaves=233; min_data_in_leaf=432; min_gain_to_split=0; min_sum_hessian_in_leaf=9.53; max_depth=12; bagging_fraction=0.975; lambda_l1=3.04; lambda_l2=3.96; scale_pos_weight=22.4 : y = 0.928 : 45.0 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:45:53 2025 AUC 0.928715674371642\n",
      "\n",
      "[mbo] 64: num_iterations=1853; learning_rate=0.0401; feature_fraction=0.778; num_leaves=125; min_data_in_leaf=599; min_gain_to_split=4; min_sum_hessian_in_leaf=3.25; max_depth=7; bagging_fraction=0.925; lambda_l1=2.51; lambda_l2=4.56; scale_pos_weight=8.84 : y = 0.929 : 30.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:46:14 2025 AUC 0.919680814928674\n",
      "\n",
      "[mbo] 65: num_iterations=1164; learning_rate=0.0302; feature_fraction=0.966; num_leaves=110; min_data_in_leaf=2023; min_gain_to_split=5; min_sum_hessian_in_leaf=9.31; max_depth=1; bagging_fraction=0.838; lambda_l1=2.7; lambda_l2=4.44; scale_pos_weight=17.4 : y = 0.92 : 18.0 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:47:06 2025 AUC 0.927280860003599\n",
      "\n",
      "[mbo] 66: num_iterations=851; learning_rate=0.0401; feature_fraction=0.557; num_leaves=1514; min_data_in_leaf=930; min_gain_to_split=0; min_sum_hessian_in_leaf=3.52; max_depth=9; bagging_fraction=0.863; lambda_l1=4.39; lambda_l2=0.313; scale_pos_weight=43.9 : y = 0.927 : 48.9 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:47:33 2025 AUC 0.926584332343479\n",
      "\n",
      "[mbo] 67: num_iterations=1136; learning_rate=0.0647; feature_fraction=0.756; num_leaves=512; min_data_in_leaf=742; min_gain_to_split=5; min_sum_hessian_in_leaf=6.64; max_depth=15; bagging_fraction=0.893; lambda_l1=2.73; lambda_l2=2.84; scale_pos_weight=93 : y = 0.927 : 23.3 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:47:55 2025 AUC 0.928881851897953\n",
      "\n",
      "[mbo] 68: num_iterations=351; learning_rate=0.0145; feature_fraction=0.713; num_leaves=538; min_data_in_leaf=634; min_gain_to_split=0; min_sum_hessian_in_leaf=4.05; max_depth=15; bagging_fraction=0.874; lambda_l1=3.66; lambda_l2=0.288; scale_pos_weight=30.3 : y = 0.929 : 19.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:48:25 2025 AUC 0.925467076254607\n",
      "\n",
      "[mbo] 69: num_iterations=752; learning_rate=0.0258; feature_fraction=0.739; num_leaves=1255; min_data_in_leaf=3413; min_gain_to_split=0; min_sum_hessian_in_leaf=9.85; max_depth=15; bagging_fraction=0.801; lambda_l1=2.15; lambda_l2=0.255; scale_pos_weight=26.7 : y = 0.925 : 26.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:48:44 2025 AUC 0.92907060102543\n",
      "\n",
      "[mbo] 70: num_iterations=522; learning_rate=0.0358; feature_fraction=0.754; num_leaves=1327; min_data_in_leaf=605; min_gain_to_split=4; min_sum_hessian_in_leaf=6.71; max_depth=8; bagging_fraction=0.745; lambda_l1=4.62; lambda_l2=4.87; scale_pos_weight=6.53 : y = 0.929 : 15.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:50:34 2025 AUC 0.928769641704287\n",
      "\n",
      "[mbo] 74: num_iterations=1267; learning_rate=0.0324; feature_fraction=0.741; num_leaves=1261; min_data_in_leaf=894; min_gain_to_split=4; min_sum_hessian_in_leaf=8.77; max_depth=15; bagging_fraction=0.983; lambda_l1=4.66; lambda_l2=3.89; scale_pos_weight=6.53 : y = 0.929 : 28.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:51:00 2025 AUC 0.928732705522608\n",
      "\n",
      "[mbo] 75: num_iterations=990; learning_rate=0.0354; feature_fraction=0.756; num_leaves=1575; min_data_in_leaf=461; min_gain_to_split=4; min_sum_hessian_in_leaf=8.88; max_depth=12; bagging_fraction=0.786; lambda_l1=1.73; lambda_l2=4.99; scale_pos_weight=7.25 : y = 0.929 : 22.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:51:40 2025 AUC 0.929653010609962\n",
      "\n",
      "[mbo] 76: num_iterations=1835; learning_rate=0.0367; feature_fraction=0.791; num_leaves=345; min_data_in_leaf=528; min_gain_to_split=3; min_sum_hessian_in_leaf=8.16; max_depth=15; bagging_fraction=0.767; lambda_l1=2.63; lambda_l2=4.9; scale_pos_weight=13.6 : y = 0.93 : 36.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:52:21 2025 AUC 0.92734491530856\n",
      "\n",
      "[mbo] 77: num_iterations=1896; learning_rate=0.0265; feature_fraction=0.829; num_leaves=515; min_data_in_leaf=2000; min_gain_to_split=1; min_sum_hessian_in_leaf=4.02; max_depth=14; bagging_fraction=0.706; lambda_l1=2.9; lambda_l2=3.99; scale_pos_weight=3.02 : y = 0.927 : 38.3 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:52:57 2025 AUC 0.928930564340991\n",
      "\n",
      "[mbo] 78: num_iterations=1023; learning_rate=0.0337; feature_fraction=0.791; num_leaves=568; min_data_in_leaf=853; min_gain_to_split=2; min_sum_hessian_in_leaf=8.44; max_depth=15; bagging_fraction=0.856; lambda_l1=3.29; lambda_l2=4.79; scale_pos_weight=45.2 : y = 0.929 : 32.3 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:53:31 2025 AUC 0.929739268385233\n",
      "\n",
      "[mbo] 79: num_iterations=1762; learning_rate=0.0376; feature_fraction=0.703; num_leaves=1680; min_data_in_leaf=483; min_gain_to_split=3; min_sum_hessian_in_leaf=8.65; max_depth=11; bagging_fraction=0.64; lambda_l1=3.61; lambda_l2=4.76; scale_pos_weight=2.92 : y = 0.93 : 30.5 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:54:01 2025 AUC 0.928780102159547\n",
      "\n",
      "[mbo] 80: num_iterations=1168; learning_rate=0.0313; feature_fraction=0.747; num_leaves=1359; min_data_in_leaf=760; min_gain_to_split=3; min_sum_hessian_in_leaf=8.68; max_depth=9; bagging_fraction=0.87; lambda_l1=3.27; lambda_l2=4.8; scale_pos_weight=6.91 : y = 0.929 : 26.4 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:54:35 2025 AUC 0.928612130604517\n",
      "\n",
      "[mbo] 81: num_iterations=1734; learning_rate=0.0453; feature_fraction=0.755; num_leaves=1610; min_data_in_leaf=808; min_gain_to_split=5; min_sum_hessian_in_leaf=8.43; max_depth=15; bagging_fraction=0.607; lambda_l1=4.64; lambda_l2=4.74; scale_pos_weight=11 : y = 0.929 : 31.0 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:55:18 2025 AUC 0.92933043819149\n",
      "\n",
      "[mbo] 82: num_iterations=1924; learning_rate=0.0152; feature_fraction=0.793; num_leaves=384; min_data_in_leaf=804; min_gain_to_split=4; min_sum_hessian_in_leaf=9.39; max_depth=14; bagging_fraction=0.982; lambda_l1=0.511; lambda_l2=4.9; scale_pos_weight=2.62 : y = 0.929 : 39.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:56:13 2025 AUC 0.92882175868218\n",
      "\n",
      "[mbo] 83: num_iterations=2013; learning_rate=0.0315; feature_fraction=0.645; num_leaves=1640; min_data_in_leaf=681; min_gain_to_split=3; min_sum_hessian_in_leaf=8.52; max_depth=15; bagging_fraction=0.683; lambda_l1=3.32; lambda_l2=3.53; scale_pos_weight=16 : y = 0.929 : 51.5 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:56:39 2025 AUC 0.928927232948794\n",
      "\n",
      "[mbo] 84: num_iterations=591; learning_rate=0.0402; feature_fraction=0.593; num_leaves=1352; min_data_in_leaf=660; min_gain_to_split=4; min_sum_hessian_in_leaf=3.51; max_depth=15; bagging_fraction=0.768; lambda_l1=2.35; lambda_l2=1.45; scale_pos_weight=10 : y = 0.929 : 22.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:57:34 2025 AUC 0.928398112276862\n",
      "\n",
      "[mbo] 85: num_iterations=568; learning_rate=0.0366; feature_fraction=0.69; num_leaves=1826; min_data_in_leaf=32; min_gain_to_split=0; min_sum_hessian_in_leaf=6.13; max_depth=12; bagging_fraction=0.766; lambda_l1=3.02; lambda_l2=4.65; scale_pos_weight=9.83 : y = 0.928 : 52.3 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:58:01 2025 AUC 0.92853197789492\n",
      "\n",
      "[mbo] 86: num_iterations=1013; learning_rate=0.0367; feature_fraction=0.696; num_leaves=1754; min_data_in_leaf=499; min_gain_to_split=2; min_sum_hessian_in_leaf=8.32; max_depth=15; bagging_fraction=0.689; lambda_l1=3.85; lambda_l2=4.92; scale_pos_weight=2.36 : y = 0.929 : 23.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 02:58:38 2025 AUC 0.927381206984138\n",
      "\n",
      "[mbo] 87: num_iterations=524; learning_rate=0.0427; feature_fraction=0.683; num_leaves=498; min_data_in_leaf=665; min_gain_to_split=0; min_sum_hessian_in_leaf=2.58; max_depth=15; bagging_fraction=0.851; lambda_l1=2.13; lambda_l2=1.13; scale_pos_weight=74.3 : y = 0.927 : 32.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 03:00:04 2025 AUC 0.928419975261536\n",
      "\n",
      "[mbo] 88: num_iterations=1925; learning_rate=0.0933; feature_fraction=0.501; num_leaves=1960; min_data_in_leaf=449; min_gain_to_split=3; min_sum_hessian_in_leaf=5.84; max_depth=6; bagging_fraction=0.504; lambda_l1=4.69; lambda_l2=4.99; scale_pos_weight=2.47 : y = 0.928 : 81.8 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 89 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Sep 03 03:01:14 2025 AUC 0.927751257471946\n",
      "\n",
      "[mbo] 89: num_iterations=1754; learning_rate=0.0439; feature_fraction=0.61; num_leaves=1637; min_data_in_leaf=209; min_gain_to_split=4; min_sum_hessian_in_leaf=5.65; max_depth=11; bagging_fraction=0.729; lambda_l1=3.69; lambda_l2=4.86; scale_pos_weight=12.8 : y = 0.928 : 58.7 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 03:02:04 2025 AUC 0.930868238611394\n",
      "\n",
      "[mbo] 90: num_iterations=1676; learning_rate=0.0325; feature_fraction=0.713; num_leaves=1556; min_data_in_leaf=782; min_gain_to_split=3; min_sum_hessian_in_leaf=9.21; max_depth=13; bagging_fraction=0.872; lambda_l1=2.99; lambda_l2=3.33; scale_pos_weight=7.27 : y = 0.931 : 45.5 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 03:02:45 2025 AUC 0.929119113370176\n",
      "\n",
      "[mbo] 91: num_iterations=1766; learning_rate=0.0355; feature_fraction=0.715; num_leaves=1503; min_data_in_leaf=915; min_gain_to_split=3; min_sum_hessian_in_leaf=9.64; max_depth=14; bagging_fraction=0.907; lambda_l1=2.08; lambda_l2=4.73; scale_pos_weight=5.35 : y = 0.929 : 38.1 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 03:03:20 2025 AUC 0.929185043422564\n",
      "\n",
      "[mbo] 92: num_iterations=1664; learning_rate=0.0324; feature_fraction=0.74; num_leaves=1831; min_data_in_leaf=488; min_gain_to_split=3; min_sum_hessian_in_leaf=4.11; max_depth=14; bagging_fraction=0.835; lambda_l1=3.48; lambda_l2=0.542; scale_pos_weight=2.09 : y = 0.929 : 31.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 03:04:07 2025 AUC 0.929210013770881\n",
      "\n",
      "[mbo] 93: num_iterations=1902; learning_rate=0.0211; feature_fraction=0.78; num_leaves=1345; min_data_in_leaf=340; min_gain_to_split=2; min_sum_hessian_in_leaf=8.71; max_depth=10; bagging_fraction=0.876; lambda_l1=4.24; lambda_l2=3.59; scale_pos_weight=5.39 : y = 0.929 : 43.9 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 03:05:30 2025 AUC 0.923983555690556\n",
      "\n",
      "[mbo] 94: num_iterations=1905; learning_rate=0.101; feature_fraction=0.504; num_leaves=1698; min_data_in_leaf=2875; min_gain_to_split=2; min_sum_hessian_in_leaf=8.6; max_depth=10; bagging_fraction=0.529; lambda_l1=3.85; lambda_l2=1.37; scale_pos_weight=1.08 : y = 0.924 : 79.6 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 03:06:40 2025 AUC 0.923830177888103\n",
      "\n",
      "[mbo] 95: num_iterations=1075; learning_rate=0.00298; feature_fraction=0.69; num_leaves=1666; min_data_in_leaf=693; min_gain_to_split=3; min_sum_hessian_in_leaf=8.97; max_depth=15; bagging_fraction=0.915; lambda_l1=1.9; lambda_l2=0.863; scale_pos_weight=41 : y = 0.924 : 65.3 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 03:07:53 2025 AUC 0.926589027970237\n",
      "\n",
      "[mbo] 96: num_iterations=1627; learning_rate=0.0741; feature_fraction=0.503; num_leaves=1908; min_data_in_leaf=136; min_gain_to_split=3; min_sum_hessian_in_leaf=2.55; max_depth=13; bagging_fraction=0.516; lambda_l1=3.69; lambda_l2=2.62; scale_pos_weight=4.29 : y = 0.927 : 68.8 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 03:10:16 2025 AUC 0.925603874430882\n",
      "\n",
      "[mbo] 98: num_iterations=1392; learning_rate=0.0922; feature_fraction=0.534; num_leaves=1891; min_data_in_leaf=235; min_gain_to_split=4; min_sum_hessian_in_leaf=4.57; max_depth=3; bagging_fraction=0.825; lambda_l1=4.68; lambda_l2=3.31; scale_pos_weight=1.19 : y = 0.926 : 58.9 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 99 in the file bayesiana.RDATA.\n",
      "\n",
      "Wed Sep 03 03:10:49 2025 AUC 0.925922899772653\n",
      "\n",
      "[mbo] 99: num_iterations=1488; learning_rate=0.0346; feature_fraction=0.796; num_leaves=1615; min_data_in_leaf=236; min_gain_to_split=4; min_sum_hessian_in_leaf=6.73; max_depth=13; bagging_fraction=0.56; lambda_l1=2.95; lambda_l2=3.35; scale_pos_weight=1.33 : y = 0.926 : 24.2 secs : infill_ei\n",
      "\n",
      "Wed Sep 03 03:11:32 2025 AUC 0.926008450714353\n",
      "\n",
      "[mbo] 100: num_iterations=1920; learning_rate=0.0322; feature_fraction=0.749; num_leaves=655; min_data_in_leaf=3084; min_gain_to_split=2; min_sum_hessian_in_leaf=2.65; max_depth=15; bagging_fraction=0.891; lambda_l1=2.99; lambda_l2=0.0502; scale_pos_weight=9.81 : y = 0.926 : 38.8 secs : infill_ei\n",
      "\n",
      "Saved the final state in the file bayesiana.RDATA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "# es la celda mas lenta de todo el notebook\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ssk5nnMk6INK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'num_iterations'</li><li>'learning_rate'</li><li>'feature_fraction'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'min_gain_to_split'</li><li>'min_sum_hessian_in_leaf'</li><li>'max_depth'</li><li>'bagging_fraction'</li><li>'lambda_l1'</li><li>'lambda_l2'</li><li>'scale_pos_weight'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_iterations'\n",
       "\\item 'learning\\_rate'\n",
       "\\item 'feature\\_fraction'\n",
       "\\item 'num\\_leaves'\n",
       "\\item 'min\\_data\\_in\\_leaf'\n",
       "\\item 'min\\_gain\\_to\\_split'\n",
       "\\item 'min\\_sum\\_hessian\\_in\\_leaf'\n",
       "\\item 'max\\_depth'\n",
       "\\item 'bagging\\_fraction'\n",
       "\\item 'lambda\\_l1'\n",
       "\\item 'lambda\\_l2'\n",
       "\\item 'scale\\_pos\\_weight'\n",
       "\\item 'y'\n",
       "\\item 'dob'\n",
       "\\item 'eol'\n",
       "\\item 'error.message'\n",
       "\\item 'exec.time'\n",
       "\\item 'ei'\n",
       "\\item 'error.model'\n",
       "\\item 'train.time'\n",
       "\\item 'prop.type'\n",
       "\\item 'propose.time'\n",
       "\\item 'se'\n",
       "\\item 'mean'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_iterations'\n",
       "2. 'learning_rate'\n",
       "3. 'feature_fraction'\n",
       "4. 'num_leaves'\n",
       "5. 'min_data_in_leaf'\n",
       "6. 'min_gain_to_split'\n",
       "7. 'min_sum_hessian_in_leaf'\n",
       "8. 'max_depth'\n",
       "9. 'bagging_fraction'\n",
       "10. 'lambda_l1'\n",
       "11. 'lambda_l2'\n",
       "12. 'scale_pos_weight'\n",
       "13. 'y'\n",
       "14. 'dob'\n",
       "15. 'eol'\n",
       "16. 'error.message'\n",
       "17. 'exec.time'\n",
       "18. 'ei'\n",
       "19. 'error.model'\n",
       "20. 'train.time'\n",
       "21. 'prop.type'\n",
       "22. 'propose.time'\n",
       "23. 'se'\n",
       "24. 'mean'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_iterations\"          \"learning_rate\"          \n",
       " [3] \"feature_fraction\"        \"num_leaves\"             \n",
       " [5] \"min_data_in_leaf\"        \"min_gain_to_split\"      \n",
       " [7] \"min_sum_hessian_in_leaf\" \"max_depth\"              \n",
       " [9] \"bagging_fraction\"        \"lambda_l1\"              \n",
       "[11] \"lambda_l2\"               \"scale_pos_weight\"       \n",
       "[13] \"y\"                       \"dob\"                    \n",
       "[15] \"eol\"                     \"error.message\"          \n",
       "[17] \"exec.time\"               \"ei\"                     \n",
       "[19] \"error.model\"             \"train.time\"             \n",
       "[21] \"prop.type\"               \"propose.time\"           \n",
       "[23] \"se\"                      \"mean\"                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "colnames( tb_bayesiana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "u4zq-vknhjGc"
   },
   "outputs": [],
   "source": [
    "# almaceno los resultados de la Bayesian Optimization\n",
    "# y capturo los mejores hiperparametros encontrados\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "\n",
    "tb_bayesiana[, iter := .I]\n",
    "\n",
    "# ordeno en forma descendente por AUC = y\n",
    "setorder(tb_bayesiana, -y)\n",
    "\n",
    "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
    "fwrite( tb_bayesiana,\n",
    "  file= \"BO_log.txt\",\n",
    "  sep= \"\\t\"\n",
    ")\n",
    "\n",
    "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
    "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
    "  1, # el primero es el de mejor AUC\n",
    "  setdiff(colnames(tb_bayesiana),\n",
    "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
    "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
    "  with= FALSE\n",
    "]\n",
    "\n",
    "\n",
    "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "E8v2eA427N8e"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iBTWexVU7PGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_iterations learning_rate feature_fraction num_leaves min_data_in_leaf\n",
      "            <int>         <num>            <num>      <int>            <int>\n",
      "1:           1676    0.03248403        0.7134608       1556              782\n",
      "   min_gain_to_split min_sum_hessian_in_leaf max_depth bagging_fraction\n",
      "               <int>                   <num>     <int>            <num>\n",
      "1:                 3                9.205316        13        0.8716466\n",
      "   lambda_l1 lambda_l2 scale_pos_weight\n",
      "       <num>     <num>            <num>\n",
      "1:   2.98807   3.33242         7.269816\n",
      "[1] 0.9308682\n"
     ]
    }
   ],
   "source": [
    "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
    "print(PARAM$out$lgbm$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKsVZmAnhwX-"
   },
   "source": [
    "## 2.3  Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ_C33Tr5B_9"
   },
   "source": [
    "### Final Training\n",
    "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "eDqfyA14hzwv"
   },
   "outputs": [],
   "source": [
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento <- paste0(\"exp\", PARAM$experimento)\n",
    "dir.create(experimento, showWarnings= FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qFmFivf5Iet"
   },
   "source": [
    "#### Final Training Dataset\n",
    "\n",
    "Aqui esta la gran decision de en qué meses hago el Final Training\n",
    "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lg5WVZncvc7H"
   },
   "outputs": [],
   "source": [
    "# clase01\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "yc9QzXREv0xf"
   },
   "outputs": [],
   "source": [
    "dataset_train <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "thjdqEBLuvNt"
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[, clase01]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNUa-WSz5Oqu"
   },
   "source": [
    "#### Final Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "FgCcvBfEwImu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$boosting</dt>\n",
       "\t\t<dd>'gbdt'</dd>\n",
       "\t<dt>$objective</dt>\n",
       "\t\t<dd>'binary'</dd>\n",
       "\t<dt>$metric</dt>\n",
       "\t\t<dd>'auc'</dd>\n",
       "\t<dt>$first_metric_only</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$boost_from_average</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$feature_pre_filter</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$force_row_wise</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$verbosity</dt>\n",
       "\t\t<dd>-100</dd>\n",
       "\t<dt>$seed</dt>\n",
       "\t\t<dd>100379</dd>\n",
       "\t<dt>$max_depth</dt>\n",
       "\t\t<dd>13</dd>\n",
       "\t<dt>$min_gain_to_split</dt>\n",
       "\t\t<dd>3</dd>\n",
       "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
       "\t\t<dd>9.20531619022267</dd>\n",
       "\t<dt>$lambda_l1</dt>\n",
       "\t\t<dd>2.98806975081582</dd>\n",
       "\t<dt>$lambda_l2</dt>\n",
       "\t\t<dd>3.33241974376582</dd>\n",
       "\t<dt>$max_bin</dt>\n",
       "\t\t<dd>31</dd>\n",
       "\t<dt>$bagging_fraction</dt>\n",
       "\t\t<dd>0.871646579388766</dd>\n",
       "\t<dt>$pos_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$neg_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$is_unbalance</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$scale_pos_weight</dt>\n",
       "\t\t<dd>7.26981627072346</dd>\n",
       "\t<dt>$drop_rate</dt>\n",
       "\t\t<dd>0.1</dd>\n",
       "\t<dt>$max_drop</dt>\n",
       "\t\t<dd>50</dd>\n",
       "\t<dt>$skip_drop</dt>\n",
       "\t\t<dd>0.5</dd>\n",
       "\t<dt>$extra_trees</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$num_iterations</dt>\n",
       "\t\t<dd>1676</dd>\n",
       "\t<dt>$learning_rate</dt>\n",
       "\t\t<dd>0.0324840315916701</dd>\n",
       "\t<dt>$feature_fraction</dt>\n",
       "\t\t<dd>0.713460796144398</dd>\n",
       "\t<dt>$num_leaves</dt>\n",
       "\t\t<dd>1556</dd>\n",
       "\t<dt>$min_data_in_leaf</dt>\n",
       "\t\t<dd>782</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$boosting] 'gbdt'\n",
       "\\item[\\$objective] 'binary'\n",
       "\\item[\\$metric] 'auc'\n",
       "\\item[\\$first\\_metric\\_only] FALSE\n",
       "\\item[\\$boost\\_from\\_average] TRUE\n",
       "\\item[\\$feature\\_pre\\_filter] FALSE\n",
       "\\item[\\$force\\_row\\_wise] TRUE\n",
       "\\item[\\$verbosity] -100\n",
       "\\item[\\$seed] 100379\n",
       "\\item[\\$max\\_depth] 13\n",
       "\\item[\\$min\\_gain\\_to\\_split] 3\n",
       "\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 9.20531619022267\n",
       "\\item[\\$lambda\\_l1] 2.98806975081582\n",
       "\\item[\\$lambda\\_l2] 3.33241974376582\n",
       "\\item[\\$max\\_bin] 31\n",
       "\\item[\\$bagging\\_fraction] 0.871646579388766\n",
       "\\item[\\$pos\\_bagging\\_fraction] 1\n",
       "\\item[\\$neg\\_bagging\\_fraction] 1\n",
       "\\item[\\$is\\_unbalance] FALSE\n",
       "\\item[\\$scale\\_pos\\_weight] 7.26981627072346\n",
       "\\item[\\$drop\\_rate] 0.1\n",
       "\\item[\\$max\\_drop] 50\n",
       "\\item[\\$skip\\_drop] 0.5\n",
       "\\item[\\$extra\\_trees] FALSE\n",
       "\\item[\\$num\\_iterations] 1676\n",
       "\\item[\\$learning\\_rate] 0.0324840315916701\n",
       "\\item[\\$feature\\_fraction] 0.713460796144398\n",
       "\\item[\\$num\\_leaves] 1556\n",
       "\\item[\\$min\\_data\\_in\\_leaf] 782\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$boosting\n",
       ":   'gbdt'\n",
       "$objective\n",
       ":   'binary'\n",
       "$metric\n",
       ":   'auc'\n",
       "$first_metric_only\n",
       ":   FALSE\n",
       "$boost_from_average\n",
       ":   TRUE\n",
       "$feature_pre_filter\n",
       ":   FALSE\n",
       "$force_row_wise\n",
       ":   TRUE\n",
       "$verbosity\n",
       ":   -100\n",
       "$seed\n",
       ":   100379\n",
       "$max_depth\n",
       ":   13\n",
       "$min_gain_to_split\n",
       ":   3\n",
       "$min_sum_hessian_in_leaf\n",
       ":   9.20531619022267\n",
       "$lambda_l1\n",
       ":   2.98806975081582\n",
       "$lambda_l2\n",
       ":   3.33241974376582\n",
       "$max_bin\n",
       ":   31\n",
       "$bagging_fraction\n",
       ":   0.871646579388766\n",
       "$pos_bagging_fraction\n",
       ":   1\n",
       "$neg_bagging_fraction\n",
       ":   1\n",
       "$is_unbalance\n",
       ":   FALSE\n",
       "$scale_pos_weight\n",
       ":   7.26981627072346\n",
       "$drop_rate\n",
       ":   0.1\n",
       "$max_drop\n",
       ":   50\n",
       "$skip_drop\n",
       ":   0.5\n",
       "$extra_trees\n",
       ":   FALSE\n",
       "$num_iterations\n",
       ":   1676\n",
       "$learning_rate\n",
       ":   0.0324840315916701\n",
       "$feature_fraction\n",
       ":   0.713460796144398\n",
       "$num_leaves\n",
       ":   1556\n",
       "$min_data_in_leaf\n",
       ":   782\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$boosting\n",
       "[1] \"gbdt\"\n",
       "\n",
       "$objective\n",
       "[1] \"binary\"\n",
       "\n",
       "$metric\n",
       "[1] \"auc\"\n",
       "\n",
       "$first_metric_only\n",
       "[1] FALSE\n",
       "\n",
       "$boost_from_average\n",
       "[1] TRUE\n",
       "\n",
       "$feature_pre_filter\n",
       "[1] FALSE\n",
       "\n",
       "$force_row_wise\n",
       "[1] TRUE\n",
       "\n",
       "$verbosity\n",
       "[1] -100\n",
       "\n",
       "$seed\n",
       "[1] 100379\n",
       "\n",
       "$max_depth\n",
       "[1] 13\n",
       "\n",
       "$min_gain_to_split\n",
       "[1] 3\n",
       "\n",
       "$min_sum_hessian_in_leaf\n",
       "[1] 9.205316\n",
       "\n",
       "$lambda_l1\n",
       "[1] 2.98807\n",
       "\n",
       "$lambda_l2\n",
       "[1] 3.33242\n",
       "\n",
       "$max_bin\n",
       "[1] 31\n",
       "\n",
       "$bagging_fraction\n",
       "[1] 0.8716466\n",
       "\n",
       "$pos_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$neg_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$is_unbalance\n",
       "[1] FALSE\n",
       "\n",
       "$scale_pos_weight\n",
       "[1] 7.269816\n",
       "\n",
       "$drop_rate\n",
       "[1] 0.1\n",
       "\n",
       "$max_drop\n",
       "[1] 50\n",
       "\n",
       "$skip_drop\n",
       "[1] 0.5\n",
       "\n",
       "$extra_trees\n",
       "[1] FALSE\n",
       "\n",
       "$num_iterations\n",
       "[1] 1676\n",
       "\n",
       "$learning_rate\n",
       "[1] 0.03248403\n",
       "\n",
       "$feature_fraction\n",
       "[1] 0.7134608\n",
       "\n",
       "$num_leaves\n",
       "[1] 1556\n",
       "\n",
       "$min_data_in_leaf\n",
       "[1] 782\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
    "  PARAM$out$lgbm$mejores_hiperparametros)\n",
    "\n",
    "param_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZIYn4l95TBH"
   },
   "source": [
    "#### Training\n",
    "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vPLsd4mMRe4u"
   },
   "outputs": [],
   "source": [
    "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
    "\n",
    "param_normalizado <- copy(param_final)\n",
    "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WRI_-taRwOXO"
   },
   "outputs": [],
   "source": [
    "  # entreno LightGBM\n",
    "\n",
    "  modelo_final <- lgb.train(\n",
    "    data= dtrain,\n",
    "    param= param_normalizado\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_bkhnCvj0g3Q"
   },
   "outputs": [],
   "source": [
    "# ahora imprimo la importancia de variables\n",
    "\n",
    "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
    "archivo_importancia <- \"impo.txt\"\n",
    "\n",
    "fwrite(tb_importancia,\n",
    "  file= archivo_importancia,\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lZ3sLmbh0kFj"
   },
   "outputs": [],
   "source": [
    "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
    "\n",
    "lgb.save(modelo_final, \"modelo.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEtp2--t5Ymg"
   },
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI5008Mj5ZdI"
   },
   "source": [
    "Aplico el modelo final a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "PimBY3N_0ryP"
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes == 202109]\n",
    "\n",
    "# aplico el modelo a los datos nuevos\n",
    "prediccion <- predict(\n",
    "  modelo_final,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D26rNRh55gpw"
   },
   "source": [
    "#### Tabla Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "RJwg7LHd11yu"
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOt4eG_55ltv"
   },
   "source": [
    "Kaggle Competition Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "gWW3tatE12je"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
      "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
      "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
      "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
      "Successfully submitted to Data Mining, Analista Sr 2025 B \n"
     ]
    }
   ],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "# suba TODOS los archivos a Kaggle\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "dir.create(\"kaggle\")\n",
    "\n",
    "for (envios in PARAM$kaggle$cortes) {\n",
    "\n",
    "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
    "\n",
    "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "    file= archivo_kaggle,\n",
    "    sep= \",\"\n",
    "  )\n",
    "\n",
    "  # subida a Kaggle, armo la linea de comando\n",
    "  comando <- \"kaggle competitions submit\"\n",
    "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
    "  arch <- paste( \"-f\", archivo_kaggle)\n",
    "\n",
    "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
    "  \"  semilla=\", PARAM$semilla_primigenia,\n",
    "    \"'\" )\n",
    "\n",
    "  linea <- paste( comando, competencia, arch, mensaje)\n",
    "\n",
    "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
    "  cat(salida, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "B9tB2X4439Hg"
   },
   "outputs": [],
   "source": [
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "9zA_W25c15DP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Wed Sep 03 03:12:25 2025'"
      ],
      "text/latex": [
       "'Wed Sep 03 03:12:25 2025'"
      ],
      "text/markdown": [
       "'Wed Sep 03 03:12:25 2025'"
      ],
      "text/plain": [
       "[1] \"Wed Sep 03 03:12:25 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdVZucdLHzZ0"
   },
   "source": [
    "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
    "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
